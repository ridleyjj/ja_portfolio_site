<!DOCTYPE html>
<html  dir="ltr">

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Sonic Gestures: Investigating Joy in Physical Sound
Interactions<br><br></title>
        <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
        <link rel="apple-touch-icon-precomposed" href="images/apple-touch-icon.png">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/uikit/2.26.4/css/uikit.gradient.css">

        <!-- <link rel="stylesheet" href="style.css"> -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/style.css">
        <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />
        <script src="https://code.jquery.com/jquery-2.2.1.min.js"></script>
        <!-- <script src="uikit.js"></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/uikit.js"></script>
        <!-- <script src="scripts.js"></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/scripts.js"></script>
        <!-- <script src="jquery.sticky-kit.js "></script> -->
        <script src="https://cdn.jsdelivr.net/gh/diversen/pandoc-uikit@master/jquery.sticky-kit.js"></script>

        <meta name="generator" content="pandoc-uikit" />
                <meta name="author" content="Submitted in Partial Fulfilment of MSc Sound Design at The University of Edinburgh.    Jack Ridley" />
                        <title>Sonic Gestures: Investigating Joy in Physical Sound Interactions  </title>
        <style type="text/css">code{white-space: pre;}</style>
                                                        </head>

    <body>


        <div class="uk-container uk-container-center uk-margin-top uk-margin-large-bottom">

                        <div class="uk-grid" data-uk-grid-margin>
                <div class="uk-width-1-1">
                    <h1 class="uk-heading-large">Sonic Gestures:
Investigating Joy in Physical Sound Interactions<br><br></h1>
                                                            <p class="uk-text-large">Submitted
in Partial Fulfilment of MSc Sound Design at The University of
Edinburgh.<br><br><br><br><strong>Jack Ridley</strong></p>
                                    </div>
            </div>
            
            <div class="uk-grid" data-uk-grid-margin >
                <div class="uk-width-medium-1-4">
                    <div class="uk-overflow-container" data-uk-sticky="{top:25,media: 768}">
                        <div class="uk-panel uk-panel-box menu-begin" >

                                                        <ul>
                                                        <li><a
                                                        href="#introduction"
                                                        id="toc-introduction">Introduction</a>
                                                        <ul>
                                                        <li><a
                                                        href="#my-interest-and-inspiration"
                                                        id="toc-my-interest-and-inspiration">My
                                                        interest and
                                                        inspiration</a></li>
                                                        <li><a
                                                        href="#my-aims-with-this-project"
                                                        id="toc-my-aims-with-this-project">My
                                                        aims with this
                                                        project</a></li>
                                                        <li><a
                                                        href="#context"
                                                        id="toc-context">Context</a></li>
                                                        <li><a
                                                        href="#how-to-read-this-dissertation"
                                                        id="toc-how-to-read-this-dissertation">How
                                                        to read this
                                                        dissertation</a></li>
                                                        <li><a
                                                        href="#note-on-my-approach-to-the-project-structure"
                                                        id="toc-note-on-my-approach-to-the-project-structure">Note
                                                        on my approach
                                                        to the project
                                                        structure</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#chapter-1-joy-through-the-intuitive"
                                                        id="toc-chapter-1-joy-through-the-intuitive">Chapter
                                                        1: Joy Through
                                                        the
                                                        Intuitive</a>
                                                        <ul>
                                                        <li><a
                                                        href="#theory---don-normans-psychology-of-design"
                                                        id="toc-theory---don-normans-psychology-of-design">Theory
                                                        - Don Norman’s
                                                        Psychology of
                                                        Design</a></li>
                                                        <li><a
                                                        href="#experiment-1.1---dial-music"
                                                        id="toc-experiment-1.1---dial-music">Experiment
                                                        1.1 - Dial
                                                        Music</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method"
                                                        id="toc-experimental-method"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation"
                                                        id="toc-resultsevaluation"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#experiment-1.2---sampler"
                                                        id="toc-experiment-1.2---sampler">Experiment
                                                        1.2 -
                                                        Sampler</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-1"
                                                        id="toc-experimental-method-1"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-1"
                                                        id="toc-resultsevaluation-1"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#experiment-1.3---piano-clouds"
                                                        id="toc-experiment-1.3---piano-clouds">Experiment
                                                        1.3 - Piano
                                                        Clouds</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-2"
                                                        id="toc-experimental-method-2"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-2"
                                                        id="toc-resultsevaluation-2"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#chapter-2-joy-through-complexity-and-challenge"
                                                        id="toc-chapter-2-joy-through-complexity-and-challenge">Chapter
                                                        2: Joy Through
                                                        Complexity and
                                                        Challenge</a>
                                                        <ul>
                                                        <li><a
                                                        href="#theory---complexity-through-interface-and-conceptualisation"
                                                        id="toc-theory---complexity-through-interface-and-conceptualisation">Theory
                                                        - Complexity
                                                        through
                                                        Interface and
                                                        Conceptualisation</a></li>
                                                        <li><a
                                                        href="#experiment-2.1---fx-control-via-machine-learning-mappings"
                                                        id="toc-experiment-2.1---fx-control-via-machine-learning-mappings">Experiment
                                                        2.1 - ‘FX
                                                        Control via
                                                        Machine Learning
                                                        Mappings’</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-3"
                                                        id="toc-experimental-method-3"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-3"
                                                        id="toc-resultsevaluation-3"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#experiment-2.2---formant-filters"
                                                        id="toc-experiment-2.2---formant-filters">Experiment
                                                        2.2 - ‘Formant
                                                        Filters’</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-4"
                                                        id="toc-experimental-method-4"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-4"
                                                        id="toc-resultsevaluation-4"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#experiment-2.3---concatenative-corpus-explorer"
                                                        id="toc-experiment-2.3---concatenative-corpus-explorer">Experiment
                                                        2.3 -
                                                        ‘Concatenative
                                                        Corpus
                                                        Explorer’</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-5"
                                                        id="toc-experimental-method-5"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-5"
                                                        id="toc-resultsevaluation-5"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#chapter-3-joy-through-the-embodied"
                                                        id="toc-chapter-3-joy-through-the-embodied">Chapter
                                                        3: Joy Through
                                                        the Embodied</a>
                                                        <ul>
                                                        <li><a
                                                        href="#theory---embodied-sonic-interactions-and-instruments"
                                                        id="toc-theory---embodied-sonic-interactions-and-instruments">Theory
                                                        - Embodied Sonic
                                                        Interactions and
                                                        Instruments</a></li>
                                                        <li><a
                                                        href="#experiment-3.1---fm-velocity-synth"
                                                        id="toc-experiment-3.1---fm-velocity-synth">Experiment
                                                        3.1 - ‘FM
                                                        Velocity
                                                        Synth’</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-6"
                                                        id="toc-experimental-method-6"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-6"
                                                        id="toc-resultsevaluation-6"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#experiment-3.2---scrubber-explorer"
                                                        id="toc-experiment-3.2---scrubber-explorer">Experiment
                                                        3.2 - ‘Scrubber
                                                        Explorer’</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-7"
                                                        id="toc-experimental-method-7"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-7"
                                                        id="toc-resultsevaluation-7"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#experiment-3.3---magic-spells"
                                                        id="toc-experiment-3.3---magic-spells">Experiment
                                                        3.3 - ‘Magic
                                                        Spells’</a>
                                                        <ul>
                                                        <li><a
                                                        href="#experimental-method-8"
                                                        id="toc-experimental-method-8"><strong>Experimental
                                                        Method</strong></a></li>
                                                        <li><a
                                                        href="#resultsevaluation-8"
                                                        id="toc-resultsevaluation-8"><strong>Results/Evaluation</strong></a></li>
                                                        </ul></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#conclusion"
                                                        id="toc-conclusion">Conclusion</a>
                                                        <ul>
                                                        <li><a
                                                        href="#the-future-of-this-project"
                                                        id="toc-the-future-of-this-project"><strong>The
                                                        Future of this
                                                        Project</strong></a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#bibliography"
                                                        id="toc-bibliography">Bibliography</a></li>
                                                        <li><a
                                                        href="#appendices"
                                                        id="toc-appendices">Appendices</a>
                                                        <ul>
                                                        <li><a
                                                        href="#appendix-a-video-documentation"
                                                        id="toc-appendix-a-video-documentation">Appendix
                                                        A: Video
                                                        Documentation</a>
                                                        <ul>
                                                        <li><a
                                                        href="#section-1-initial-pre-leapmotion-tests"
                                                        id="toc-section-1-initial-pre-leapmotion-tests">Section
                                                        1: Initial
                                                        (Pre-LeapMotion)
                                                        Tests</a></li>
                                                        <li><a
                                                        href="#section-2-pinch-sine-waves-demos"
                                                        id="toc-section-2-pinch-sine-waves-demos">Section
                                                        2: Pinch Sine
                                                        Waves
                                                        Demos</a></li>
                                                        <li><a
                                                        href="#section-3-leapmotion-wekinator-experiments"
                                                        id="toc-section-3-leapmotion-wekinator-experiments">Section
                                                        3: LeapMotion +
                                                        Wekinator
                                                        Experiments</a></li>
                                                        <li><a
                                                        href="#section-4-fm-velocity-synth"
                                                        id="toc-section-4-fm-velocity-synth">Section
                                                        4: FM Velocity
                                                        Synth</a></li>
                                                        <li><a
                                                        href="#section-5-formant-filters"
                                                        id="toc-section-5-formant-filters">Section
                                                        5: Formant
                                                        Filters</a></li>
                                                        <li><a
                                                        href="#section-6-concatenative-synthesis"
                                                        id="toc-section-6-concatenative-synthesis">Section
                                                        6: Concatenative
                                                        Synthesis</a></li>
                                                        <li><a
                                                        href="#section-7-theremin"
                                                        id="toc-section-7-theremin">Section
                                                        7:
                                                        Theremin</a></li>
                                                        <li><a
                                                        href="#section-8-sampler"
                                                        id="toc-section-8-sampler">Section
                                                        8:
                                                        Sampler</a></li>
                                                        <li><a
                                                        href="#section-9-scrubbing-record-scratcher"
                                                        id="toc-section-9-scrubbing-record-scratcher">Section
                                                        9: Scrubbing
                                                        (Record
                                                        Scratcher)</a></li>
                                                        <li><a
                                                        href="#section-10-scrubbing-explorer"
                                                        id="toc-section-10-scrubbing-explorer">Section
                                                        10: Scrubbing
                                                        (Explorer)</a></li>
                                                        <li><a
                                                        href="#section-11-magic-spells"
                                                        id="toc-section-11-magic-spells">Section
                                                        11: Magic
                                                        Spells</a></li>
                                                        <li><a
                                                        href="#section-12-piano-clouds"
                                                        id="toc-section-12-piano-clouds">Section
                                                        12: Piano
                                                        Clouds</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#appendix-b-audio-documentation"
                                                        id="toc-appendix-b-audio-documentation">Appendix
                                                        B: Audio
                                                        Documentation</a>
                                                        <ul>
                                                        <li><a
                                                        href="#section-1-andrew-play-testing-interviews"
                                                        id="toc-section-1-andrew-play-testing-interviews">Section
                                                        1: Andrew Play
                                                        Testing
                                                        Interviews</a></li>
                                                        <li><a
                                                        href="#section-2-lyla-play-testing-interviews"
                                                        id="toc-section-2-lyla-play-testing-interviews">Section
                                                        2: Lyla Play
                                                        Testing
                                                        Interviews</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#appendix-c-max-patches"
                                                        id="toc-appendix-c-max-patches">Appendix
                                                        C: Max
                                                        Patches</a></li>
                                                        <li><a
                                                        href="#appendix-d-other-software"
                                                        id="toc-appendix-d-other-software">Appendix
                                                        D: Other
                                                        Software</a></li>
                                                        <li><a
                                                        href="#appendix-e-blog-posts"
                                                        id="toc-appendix-e-blog-posts">Appendix
                                                        E: Blog
                                                        Posts</a>
                                                        <ul>
                                                        <li><a
                                                        href="#item-1-sound-designed-futures-conference-30052022"
                                                        id="toc-item-1-sound-designed-futures-conference-30052022"><strong>Item
                                                        1:</strong>
                                                        Sound Design(ed)
                                                        Futures
                                                        Conference
                                                        (30/05/2022)</a></li>
                                                        <li><a
                                                        href="#item-2-play-testing-questionnaire-setup-and-evaluation-19082022"
                                                        id="toc-item-2-play-testing-questionnaire-setup-and-evaluation-19082022"><strong>Item
                                                        2:</strong> Play
                                                        Testing
                                                        Questionnaire,
                                                        Setup, and
                                                        Evaluation
                                                        (19/08/2022)</a></li>
                                                        <li><a
                                                        href="#item-3-technical-notes-for-experiment-1.1"
                                                        id="toc-item-3-technical-notes-for-experiment-1.1"><strong>Item
                                                        3:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        1.1</a></li>
                                                        <li><a
                                                        href="#item-4-technical-notes-for-experiment-1.2"
                                                        id="toc-item-4-technical-notes-for-experiment-1.2"><strong>Item
                                                        4:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        1.2</a></li>
                                                        <li><a
                                                        href="#item-5-technical-notes-for-experiment-1.3"
                                                        id="toc-item-5-technical-notes-for-experiment-1.3"><strong>Item
                                                        5:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        1.3</a></li>
                                                        <li><a
                                                        href="#item-6-technical-notes-for-experiment-2.1"
                                                        id="toc-item-6-technical-notes-for-experiment-2.1"><strong>Item
                                                        6:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        2.1</a></li>
                                                        <li><a
                                                        href="#item-7-techinical-notes-for-experiment-2.2"
                                                        id="toc-item-7-techinical-notes-for-experiment-2.2"><strong>Item
                                                        7:</strong>
                                                        Techinical Notes
                                                        for Experiment
                                                        2.2</a></li>
                                                        <li><a
                                                        href="#item-8-technical-notes-for-experiment-2.3"
                                                        id="toc-item-8-technical-notes-for-experiment-2.3"><strong>Item
                                                        8:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        2.3</a></li>
                                                        <li><a
                                                        href="#item-9-technical-notes-for-experiment-3.1"
                                                        id="toc-item-9-technical-notes-for-experiment-3.1"><strong>Item
                                                        9:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        3.1</a></li>
                                                        <li><a
                                                        href="#item-10-technical-notes-for-experiment-3.2"
                                                        id="toc-item-10-technical-notes-for-experiment-3.2"><strong>Item
                                                        10:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        3.2</a></li>
                                                        <li><a
                                                        href="#item-11-technical-notes-for-experiment-3.3"
                                                        id="toc-item-11-technical-notes-for-experiment-3.3"><strong>Item
                                                        11:</strong>
                                                        Technical Notes
                                                        for Experiment
                                                        3.3</a></li>
                                                        <li><a
                                                        href="#item-12-the-failures-of-this-project"
                                                        id="toc-item-12-the-failures-of-this-project"><strong>Item
                                                        12:</strong> The
                                                        Failures of this
                                                        Project</a></li>
                                                        <li><a
                                                        href="#item-13-the-future-of-this-project"
                                                        id="toc-item-13-the-future-of-this-project"><strong>Item
                                                        13:</strong> The
                                                        Future of This
                                                        Project</a></li>
                                                        <li><a
                                                        href="#item-14-my-design-take-aways"
                                                        id="toc-item-14-my-design-take-aways"><strong>Item
                                                        14:</strong> My
                                                        design
                                                        take-aways</a></li>
                                                        <li><a
                                                        href="#item-15-a-note-on-my-role-within-this-project"
                                                        id="toc-item-15-a-note-on-my-role-within-this-project"><strong>Item
                                                        15:</strong> A
                                                        Note on My Role
                                                        Within This
                                                        Project</a></li>
                                                        <li><a
                                                        href="#item-16-techinical-note-on-how-i-connected-the-leapmotion-to-max-msp"
                                                        id="toc-item-16-techinical-note-on-how-i-connected-the-leapmotion-to-max-msp"><strong>Item
                                                        16:</strong>
                                                        Techinical Note
                                                        on How I
                                                        Connected the
                                                        LeapMotion to
                                                        Max MSP</a></li>
                                                        <li><a
                                                        href="#item-17-a-note-on-joy-through-surprise"
                                                        id="toc-item-17-a-note-on-joy-through-surprise"><strong>Item
                                                        17:</strong> A
                                                        Note on Joy
                                                        Through
                                                        Surprise</a></li>
                                                        </ul></li>
                                                        <li><a
                                                        href="#appendix-f-quotes"
                                                        id="toc-appendix-f-quotes">Appendix
                                                        F: Quotes</a>
                                                        <ul>
                                                        <li><a
                                                        href="#section-1-playtesting-quotes"
                                                        id="toc-section-1-playtesting-quotes"><strong>Section
                                                        1:</strong>
                                                        Playtesting
                                                        Quotes</a></li>
                                                        <li><a
                                                        href="#section-2-future-flavours-of-sound-festival-feedback"
                                                        id="toc-section-2-future-flavours-of-sound-festival-feedback"><strong>Section
                                                        2:</strong>
                                                        Future Flavours
                                                        of Sound
                                                        Festival
                                                        Feedback</a></li>
                                                        <li><a
                                                        href="#section-3-some-influential-quotes-from-relevant-literature"
                                                        id="toc-section-3-some-influential-quotes-from-relevant-literature"><strong>Section
                                                        3:</strong> Some
                                                        Influential
                                                        Quotes from
                                                        Relevant
                                                        Literature</a></li>
                                                        </ul></li>
                                                        </ul></li>
                                                        </ul>
                            
                        </div>
                    </div>
                </div>

                <div class="uk-width-medium-3-4">
<h1 id="introduction">Introduction</h1>
<blockquote>
<p>“<strong>Funny</strong> is often better than
<strong>serious</strong>… <strong>wit</strong> is never a bad thing in
design! It can offer humour, interest, commentary, or
<strong>whimsy</strong> (an art in itself).” - Perry Cook<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<h2 id="my-interest-and-inspiration">My interest and inspiration</h2>
<p>This project was initially born from an interest in physical sound
interactions. I understand physical sound interactions to refer broadly
to any interaction where a sonic output is produced based on input data
from a physical gesture or action. In this project I will be using the
term physical sound interactions to refer more specifically to physical
interactions with digital sound systems. I also focus my discussion on
those interactions where the physical actions themselves act as the
interface between user and sound, rather than the physical action moving
a visible slider for example, where there is still physical input being
transferred to sonic output, but the presence of a static interface
mediates the connections between action and sound. Therefore from here
on unless stated otherwise, by physical sound interactions I refer to
what might be more accurately described real-time physical interactions
with digital sound.</p>
<p>My interest in this type of sonic encounter comes from personal
experiences where these kinds of interactions have felt like they elicit
a unique type of joy and fun. My earlier study in performance art at
QMUL sparked an interest in participatory and interactive performance
forms such as Punchdrunk’s immersive productions<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, or
Janet Cardiff’s sound walks<a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>. This interest in
interactivity was then fostered in a more technical light over the past
two years as I have started working with software and hardware such as
game engines (Unity, Unreal, Wwise), visual coding environments (max
MSP, pure data), and microcontrollers (Arduino) which make it possible
to design interactive media that can be designed, tested, and iterated
upon relatively quickly using mostly just a single laptop. This project
then feels like a natural progression of this personal route of artistic
practice and research, investigating how I can bring these new technical
skills and interests into a more immediately live and physical space
that might be described as participatory live art.</p>
<h2 id="my-aims-with-this-project">My aims with this project</h2>
<p>My aims with this research project then exist in quite a personal
scope. I tried with this project to build experiments that would inform
my own design process and style within the realm of physical sound
interactions. My specific investigation areas were:</p>
<ul>
<li>How can I design more joyful physical sound interactions?</li>
<li>How can I design more meaningful physical sound interactions?</li>
</ul>
<p>These two questions have provided me with a lot of fuel and
inspiration throughout this project, but they undeniably bring up many
questions of there own with regards to how I am defining or assessing
the qualities of ‘joyful’ and ‘meaningful’. As this project ultimately
aims to inform my own personal style and design process, these terms
within this project generally refer to joyful and meaningful <em>to
me</em> as an artist, designer, and participant in my own right. I do at
points take influence from discussions with others and note how their
interpretations of experience differ from my own, but for this stage of
research running any serious studies of how a large group of
participants experienced the interactions was out of the scope and
timeline that I was working within.</p>
<h2 id="context">Context</h2>
<p>The area that my project has ended up focusing on - <strong>designing
physical sound interactions for hands</strong> - has a significant
precedent in the field of designing interfaces for digital musical and
sonic tools. Archeological evidence points to the first tools made my
humans being hand held. Therefore, it should be unsurprising to us that
many artists and designers have started their experiments with
controlling digital sounds in novel, physical ways with hand controlled
devices. It’s also worth noting that most traditional musical
instruments that have made it into our pop culture over the centuries
traditionally feature prominent use of the hands.</p>
<p>Notable designers who have created and worked with hand control
devices for digital sound that have been of influence during my project
include: Atau Tanaka,<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> Imogen Heap (and mimu),<a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> Douglas McCausland,<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>
Onyx Ashanti,<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> and Michael Waisvisz.<a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>
These artists have each been influential, largely in their broad
approaches to mapping (what parameters they choose to control with what
gestures), their performance styles (what actions they seem to lean into
and enjoy performing), and what they describe as being the aesthetic
appeal of using physical hand interfaces.</p>
<p>My project takes a slightly skewed approach to this world of
controlling digital sound with your hands, as my project began from a
specifically emotional approach of how I can gear these kinds of
interactions towards joy and fun for the user. Whilst I acknowledge that
this project has necessarily become quite personal and specific to my
own tastes, I hope that this line of research will inform ways that I
can design interactions not just to be used by myself, but also users
from the general public. This distinguishes my project from many of
these artists listed above, as many of them focused their designs on
either personal performance practice, or creating a commercial
performance tool aimed at musicians and performers.</p>
<h2 id="how-to-read-this-dissertation">How to read this
dissertation</h2>
<p>The ideal way to read this dissertation would be to read along, and
test each interaction as the max patch is referenced using a LeapMotion
camera. Of course this might not be possible, so I have tried to make
the project accessible through extensive video documentation of the
interactions in Appendix A.</p>
<p>With this project I have submitted a windows application
(LeapMotionOSC.exe - <a href="#AppendixD"><strong>Appendix D, Item
2</strong></a>) which connects a LeapMotion camera to OSC, and a series
of Max MSP Patches that contain the sound interactions that I designed
for my project. These pieces of software will allow you to play and
experience the sound interactions if you have access to a LeapMotion
camera. The max patches also contain further notes on the more technical
details of each interaction that can be seen in the visual coding and
comments.</p>
<p><em>(For info on the technical aspects of how I connected the
LeapMotion to max MSP, see</em> <a href="#AppendixE16"><strong>Appendix
E, Item 16</strong></a><em>)</em></p>
<p>During each chapter I recommend that the reader stops and watches
each video from the appendix as I reference it. I also recommend that
the reader looks at the max patches as I reference them, as inside the
max patches are comments that will enlighten the reader on some of the
more technical aspects of the interaction.</p>
<p>Due to limitations with how long this report is permitted to be, I
have had to banish many pieces of information to the Appendices. As
such, I do strongly recommend that if you as a reader find the main
writing passing over technical elements too quickly then please have a
look in the Appendices as they will often contain more relevant video
documentation and blog posts that will provide more insight into the
smaller details of what I did within this project. I will name specific
Appendix sections at the end of each chapter subsection that contain
relevant information.</p>
<h2 id="note-on-my-approach-to-the-project-structure">Note on my
approach to the project structure</h2>
<p>From the beginning of my project the experience of
<strong>joy</strong> during physical sound interactions has been at the
forefront of my interests in this area. The project has been built as a
way to find excuses to chase the experience of joy through designing
interactions with sound.</p>
<p>This has proved an interesting chase, with various stages of: trying
to identify what I mean by joy, analysing what aspects of design foster
this kind of experience, experimenting with implementing these elements
in my own designs, and finally reflecting on the successes and failures
of these experiments.</p>
<p>This format suggested to me an experimental method that would provide
an inner structure to the project:</p>
<ul>
<li>Theory that suggests an aspect of Joy within interactions</li>
<li>Experiment(s) that create sound interactions designed to incorporate
this aspect of Joy</li>
<li>The results/reflections of the experiment: success or failure, and
how it will likely influence my future designs</li>
</ul>
<p>I also like this experimental method personally from an
organisational standpoint as it makes the project in some way more
manageable for future reference: individual experiments within the
project can be more easily identified and referred to.
<br><br><br><br></p>
<hr />
<p><br><br></p>
<h1 id="chapter-1-joy-through-the-intuitive">Chapter 1: Joy Through the
Intuitive</h1>
<h2 id="theory---don-normans-psychology-of-design">Theory - Don Norman’s
Psychology of Design</h2>
<p>My initial conception of joy involved some sense of <em>ease of
use</em> - I was effectively defining joy as the absence of the negative
feelings like <strong>frustration</strong> or <strong>anger</strong>
that I thought prevent an experience from being joyful. This research
led me to Don Norman’s principles of design. Norman writes on the
psychology of designing for human beings in his well known book <em>The
Design of Everyday Things</em>.<a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a> Norman describes how
people encounter two things when they use a new object:</p>
<ul>
<li>“<strong>The Gulf of Execution</strong>, where they try to figure
out how [the thing] operates”<a href="#fn10" class="footnote-ref"
id="fnref10" role="doc-noteref"><sup>10</sup></a></li>
<li>“<strong>The Gulf of Evaluation</strong>, where they try to figure
out what happened”<a href="#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a></li>
</ul>
<p>Norman states that the job of a designer is “to help people bridge
the two gulfs.” Failing to do so might result in a person “blaming
themselves” for failure to use the device, and possibly giving up on the
interaction all together.<a href="#fn12" class="footnote-ref"
id="fnref12" role="doc-noteref"><sup>12</sup></a> Whilst not overtly
linked to joy here, these ideas felt close to my initial ideas of
<em>ease of use</em> that I personally linked to joy.</p>
<blockquote>
<p>“Both execution and evaluation can affect our emotional state.” <a
href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a></p>
</blockquote>
<p>In this discourse, execution and evaluation are driven by
<strong>goals</strong>. For Norman, the whole interaction starts with a
goal of some sort, then follows the execution trying to achieve this,
and then the evaluation to determine whether the goal has been achieved.
Crucially the evaluation stage involves the confirmation or
investigation of <em>why</em> the execution succeeded or failed. The
understanding of how an object or device works based on this evaluation
is what Norman calls a <strong>conceptual model</strong>. In order to
build this conceptual model, the device must provide
<strong>feedback</strong> - information which during the evaluations
stage will inform the person what has happened and why.</p>
<p>I’ve therefore extrapolated from these principles a personal design
framework that I used to investigate this potential for joy in
interaction. The framework prioritises these things:</p>
<ul>
<li>provide the user with a good <strong>conceptual model</strong> of
the experience</li>
<li>foster a <strong>goal setting</strong> environment within the
interaction</li>
</ul>
<p>These next three experiments demonstrate a few attempts at using this
<em>ease of use</em> framework to investigate joy in physical sound
interactions. <br><br></p>
<hr />
<h2 id="experiment-1.1---dial-music">Experiment 1.1 - Dial Music</h2>
<h3 id="experimental-method"><strong>Experimental Method</strong></h3>
<p>This experiment existed as two prototypes. The first prototype I
refer to as <em>‘Pinch Sine Waves’</em>. It can be seen/heard here:</p>
<p><a href="https://vimeo.com/716153349/07fa6fe0d9"
title="Video 2.2">Appendix A - Video 2.2: Pinch Sine Waves Prototype
01</a></p>
<p>This prototype focused on making the conceptual model for the
interaction as simple as possible. I used simple <strong>1:1
Mappings</strong> for the sound parameters.</p>
<p>I also hoped that the <strong>similarity of the rotation motion to
the real-life physical action of turning a dial to change a parameter
would make the whole action feel more intuitive</strong>.</p>
<p>To add some extra <strong>sonic interest</strong> to the interaction
I purposefully chose frequency ranges for each oscillator that would
result in audible <strong>beating frequencies</strong> between the two
oscillators when played simultaneously.</p>
<p>The second prototype I refer to as <em>‘Dial Music’</em>. It can be
seen/heard here:</p>
<p><a href="https://vimeo.com/732055948/3fef928cc2"
title="Video 2.3">Appendix A - Video 2.3: Pinch Sine Waves Prototype 02
- ‘Dial Music’</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 1</strong></a>)</p>
<p>In this prototype I tried to expand the possibilities for the
interaction by introducing musical scale through <strong>discrete
mapping</strong>.</p>
<p>I hoped here that the <strong>pre-associations</strong> that a user
might have with how to play a musical instrument might make the
interaction more <strong>intuitive</strong> by leading them to explore
<strong>familiar concepts</strong> such as melody or harmony.</p>
<p>By adding these musical possibilities, I was trying to introduce more
opportunities for the user to <strong>set themselves goals</strong> that
they could then achieve.</p>
<p>(see <a href="#AppendixE3"><strong>Appendix E: Item 3</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation"><strong>Results/Evaluation</strong></h3>
<p>I really enjoyed the <strong>tactility</strong> of the pinch action
in these prototypes - for me, the sense of physicality that this gives
the interaction was really satisfying. The fact that the volume of the
sound was loudest and most steady only when my fingers were touching
each other felt like an apt description of the way a sound fades in and
becomes more physically present as it’s volume increases.</p>
<p><strong>I liked how simple the first prototype was</strong>, the fact
that it didn’t have too much possible range meant that the
<strong>single sonic experience of beating frequencies could be really
explored</strong>. However, the lack of variety of sounds possible did
limit the amount of time I would want to play with this interaction.</p>
<p>The second prototype definitely felt like it offered <strong>longer
interaction possibilities</strong> as I wanted to spend more time trying
to make music with it. It definitely did feel good and satisfying when I
managed to (very occasionally) successfully execute an intended melodic
phrase.</p>
<p>However, I think the second prototype lost a certain pleasing
aesthetic that the first prototype had. The first prototype, while
limited felt like a single action that could be explored and made sense
as a whole. Meanwhile, the second prototype felt like a slightly more
<strong>arbitrary</strong> <strong><em>copy</em></strong> <strong>of a
musical instrument</strong>. For example, the frequency mappings felt
somewhat <strong>unnatural</strong> in the way that they had been
clamped into C Major, making me feel <strong>more aware that the
interaction was being forced into the form of a musical device in a way
that might be against it’s nature</strong>. For another example, whilst
the height being connected to octaves makes sense in terms of people
associating <em>higher</em> frequencies with <em>higher</em> positions,
the fact that a certain distance in the y-axis suddenly caused an octave
leap felt rather arbitrary. This lack of authenticity in the interaction
made it less enjoyable for me. <br><br></p>
<hr />
<h2 id="experiment-1.2---sampler">Experiment 1.2 - Sampler</h2>
<h3 id="experimental-method-1"><strong>Experimental Method</strong></h3>
<p>For this experiment I made a patch that I refer to as
<em>‘Sampler’</em>. It can be seen/heard here:</p>
<p><a href="https://vimeo.com/733388258/8ba613c884"
title="Video 8.1">Appendix A - Video 8.1: Sampler Demo</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 8</strong></a>)</p>
<p>With this experiment I again tried to make an interaction that would
make it <strong>as easy as possible for the user to create a good
conceptual model</strong>. To achieve this I kept the necessary actions
for control as simple as possible, using the <strong>one consistent
‘mechanic’</strong> of a velocity based threshold trigger for all
aspects of the interaction.</p>
<p>I also hoped that the conceptual model would be more easily
established because moving your hand fast is very <strong>similar to the
action of hitting a drum</strong>. By using drum samples in the
interaction, I hoped to encourage users to quickly make this
association.</p>
<p>I worried that the <strong>difficulty</strong> of breaking the
velocity threshold exactly on time in a musical rhythm might make users
<strong>frustrated and obstruct a joyful time</strong>, and so I
implemented a ‘quantised mode’ where the samples would be forced into a
metronome grid, so that they might sound more musically ‘in-time’ with
each other.</p>
<p>(see <a href="#AppendixE4"><strong>Appendix E: Item 4</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-1"><strong>Results/Evaluation</strong></h3>
<p>There was definite joy for me within this interaction. I think the
<strong>consistency created by having only one mechanic that is used
throughout the interaction</strong> (moving the hand fast to trigger a
sample) makes it a more <strong>relaxed</strong>,
<strong>playful</strong>, and <strong>joyful</strong> experience.</p>
<p>I also think that a large part of the joy comes from the surprise of
hearing the different samples as you move your hand around. Even though
it is quick to establish that you are playing with drums, the fact that
no visual interface indicates which sound is attached to which direction
means that you still occasionally get surprised at how big or small the
‘drum’ you just ‘hit’ is. <strong>This lack of detailed information also
perhaps makes the experience feel more playful and joyful because it
seems to encourage more random exploration rather than calculated
performance</strong>.</p>
<p>The quantise mode generally made the experience <strong>less
joyful</strong> it seems. When I presented this interaction to a few
friends, they all preferred the non-quantised mode because they wanted
the samples to feel as responsive as possible. I got some joy out of
hearing how organised the sound output was in quantise mode, even when I
was waving my hands around quite randomly. However, this mode was less
joyful for me too because whenever I played trying to only trigger a few
samples, it just felt like it was making the experience less responsive.
<br><br></p>
<hr />
<h2 id="experiment-1.3---piano-clouds">Experiment 1.3 - Piano
Clouds</h2>
<h3 id="experimental-method-2"><strong>Experimental Method</strong></h3>
<p>This experiment involves an interaction I created that I call
<em>‘Piano Clouds’</em>. It can be seen/heard here:</p>
<p><a href="link" title="Video 12.1">Appendix A - Video 12.1: Piano
Clouds Demo</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 11</strong></a>)</p>
<p>In this interaction I tried to <strong>maintain intuitiveness by
keeping the controls very simple</strong>. These limited controls were
consciously chosen as I felt like they would give the greatest sense of
expressive control with the least complex input.</p>
<p>I hoped that the simplicity of the controls would make it intuitive
and fun to use, and that the <strong>expressive control of moving
between related chords would allow musical goals to be set</strong> and
achieved by the user.</p>
<p>(see <a href="#AppendixE5"><strong>Appendix E: Item 5</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-2"><strong>Results/Evaluation</strong></h3>
<p>I enjoyed this interaction - for me I think the
<strong>simplicity</strong> of the controls allows for more joyful use
because there <strong>isn’t any stress</strong> involved in trying to
operate complex controls.</p>
<p>I did feel that it was slightly limited through the simple controls,
but <strong>aesthetically that limitation felt appropriate</strong> with
the sound: using piano notes feels like an appropriate simple/ubiquitous
sound output, and the way that they cluster together forming a kind of
musical ambience suggested a kind of slow experimental interaction
rather than one that was to be mastered by some complex skill or
technique.</p>
<p>I would be interested to develop this patch with more capability to
change the length of the piano samples triggered, to allow for slightly
more variation in sound.</p>
<h4 id="play-testing-documentation101"><strong>Play Testing
Documentation</strong><a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a></h4>
<p>This was an experiment that I managed to user test with two
participants. Here are some quotes they gave during our discussions that
I found particularly insightful:</p>
<blockquote>
<p>“it felt nice that I didn’t have to think as much with it, I can kind
of just loose myself in the tool rather than think about what I’m doing
with the tool” - Lyla</p>
</blockquote>
<blockquote>
<p>“it felt creative in that I could change how it made me feel, with
the chords and the speeds. But other than that it felt meditative
because it was so simple” - Lyla</p>
</blockquote>
<blockquote>
<p>“if you move too fast then it sounds like you’re hitting the same
note like three times and that impact, I just found it a little bit
annoying because - one, it’s not natural sounding to what an actual
piano would sound like, two, the same note being hit multiple times when
it’s not in character with the rest of what’s going on… I feel like it’s
meant to be more of a peaceful experience… but those moments would catch
me off guard” - Lyla</p>
</blockquote>
<blockquote>
<p>“I’d say that was very relaxing… it’s kind of meditative in a way” -
Andrew</p>
</blockquote>
<blockquote>
<p>“even though it’s very fun to play with, I don’t think of it as
playful. It’s more of like an experience, of being able to waft your
hands through the notes of the piano randomly” - Andrew</p>
</blockquote>
<blockquote>
<p>“I think [not having complete control over how many notes were
played] was very fun” - Andrew</p>
</blockquote>
<p><em>(more extensive lists of written quotes taken from these
discussions can be found in</em> <a href="#AppendixF1">*<strong>Appendix
F: Item 1</strong></a><em>)</em></p>
<p>User play testing videos of this interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/741239295/0947db9564"
title="Video 12.3">Appendix A - Video 12.3: Piano Clouds Play Test -
Andrew</a></p>
<p><a href="https://vimeo.com/741240876/905b1cbc73"
title="Video 12.4">Appendix A - Video 12.4: Piano Clouds Play Test -
Lyla</a></p>
<p>The full audio interviews with Andrew and Lyla just after they had
each experienced this interaction can be heard here:</p>
<p><a href="https://on.soundcloud.com/QP8V">Appendix B - Audio 1.2:
Andrew Play Test Interview - Piano Clouds</a></p>
<p><a href="https://on.soundcloud.com/aGtS">Appendix B - Audio 2.2: Lyla
Play Test Interview - Piano Clouds</a></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="chapter-2-joy-through-complexity-and-challenge">Chapter 2: Joy
Through Complexity and Challenge</h1>
<h2
id="theory---complexity-through-interface-and-conceptualisation">Theory
- Complexity through Interface and Conceptualisation</h2>
<p>My second approach to facilitating joy through physical sound
interactions came as a response to my first. Once I had the idea of joy
through <em>ease of use</em> in my head, I started to notice more and
more contrasting discussion in the areas of design and play about the
importance of <strong>challenge</strong>.</p>
<p>The idea of <strong>challenge and complexity leading to joy and
play</strong> continues with the conceptualisation of an interaction as
a series of attempts on a goal as discussed in chapter 1. This approach
is not concerned about making the achievement of set goals as painless
as possible, instead it ensures that <strong>when one goal is achieved,
it is possible for the user to set themselves a new more challenging
goal</strong>. Ideally, this increase in challenge could be repeated
<strong>indefinitely</strong>. Thus, the interaction <strong>remains
engaging</strong> through the increasing complexity and/or concentration
required of the user, even as they become familiar with the
experience.</p>
<p>This approach is maybe most clearly explored through social scientist
Mihaly Csikszentmihalyi’s concept of the ‘<strong>flow</strong>’ state.
As described by Norman:</p>
<blockquote>
<p>“One important emotional state is the one that accompanies complete
immersion into an activity, a state that the social scientist Mihaly
Csikszentmihalyi has labelled ‘flow’… When in the flow state, people
lose track of time and the outside environment. They are at one with the
task they are performing. <strong>The task, moreover, is at just the
proper level of difficulty: difficult enough to provide a challenge and
require continued attention, but not so difficult that it invokes
frustration and anxiety.</strong>” <a href="#fn15" class="footnote-ref"
id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
</blockquote>
<p>The above description of the flow state speaks strongly to my
personal ideas of a joyful interaction. Similar ideas are described by
designer Cas Holman, who designs objects to facilitate play. Holman’s
company, <em>Heroes Will Rise</em> follow the motto:</p>
<blockquote>
<p>“‘<strong><em>Easy is boring</em></strong>.’ ‘Easy’ meaning something
that doesn’t engage your thinking.” <a href="#fn16" class="footnote-ref"
id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
</blockquote>
<p>The idea that a complex interface can be <strong>joyful</strong> has
been specifically noted within the field of digital music control by
Hunt &amp; Kirk in their 2000 study on parameter mapping for musical
performance. In their analysis of taped user interviews they make the
conclusion:</p>
<blockquote>
<p>“Multiparametric interface is fun.” <a href="#fn17"
class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a></p>
</blockquote>
<p>The interface in question being one where more complex mappings meant
that the sound controls were <strong>less obvious</strong>, and the
volume control required constant energy from the user. In the
interviews, participants commented:</p>
<blockquote>
<p>[referring to the multiparametric interface] “‘This is really good
fun! Even when you’re not doing so well!’ (Tony, Session 2).” <a
href="#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a></p>
</blockquote>
<blockquote>
<p>“‘One movement controlling several things is more fun. It’s not like
a task - it’s like playing an instrument’ (Gregor, Session 1).” <a
href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a></p>
</blockquote>
<blockquote>
<p>[referring to the multiparametric interface] “‘You’re not so worried
about getting it right. You can just say <em>ah well</em> if it’s a bit
off and then adjust it. It’s less technical’ (Mark, Session 2).” <a
href="#fn20" class="footnote-ref" id="fnref20"
role="doc-noteref"><sup>20</sup></a></p>
</blockquote>
<p>These comments support this idea that somehow less simple or precise
control over the parameters seems to shift the experience from one that
is more <strong>technical and task based</strong>, to one that is more
<strong>playful and fun</strong>.</p>
<p>Holman interestingly expands this idea of complexity beyond just the
interface to <strong>the ways that an object can be used</strong>. She
describes this as the difference between a
<strong>non-open-ended</strong> ‘toy’ and an <strong>open-ended</strong>
‘toy’. In this dichotomy, the non-open-ended object could be seen as
simple because it can be used in a fewer ways (i.e. a toy car’s use will
more likely be used in ways deemed ‘appropriate’ for a car), whilst the
open-ended object takes on a complexity in the multitude of ways it
could be interpreted (i.e. clay, which when played with can be adapted
into a whole range of desired objects). Tovah Klein, Director at Barnard
Centre For Toddler Development talks about this open-endedness in a
recent documentary on Holman’s work:</p>
<blockquote>
<p>“Lots of toys are very goal oriented. They look like something,
there’s one way to play with it. So, you quickly find out it can go this
way or that way and then you’re done. So it sort of shuts down that
building on their own, pleasure and engagement and enjoyment.” <a
href="#fn21" class="footnote-ref" id="fnref21"
role="doc-noteref"><sup>21</sup></a></p>
</blockquote>
<p>From these ideas around the merits of <strong>complexity and
challenge</strong> I derived the following design principles to
investigate in my own interactions:</p>
<ul>
<li>avoid simple parameter controls in favour of <strong>complex, less
obvious mappings</strong></li>
<li>design interactions whose functions are more open to interpretation:
an <strong>open-ended</strong> experience</li>
</ul>
<p>These next three experiments demonstrate a few attempts at using this
<em>complexity and challenge</em> framework to investigate joy in
physical sound interactions. <br><br></p>
<hr />
<h2
id="experiment-2.1---fx-control-via-machine-learning-mappings">Experiment
2.1 - ‘FX Control via Machine Learning Mappings’</h2>
<h3 id="experimental-method-3"><strong>Experimental Method</strong></h3>
<p>For this experiment I made a patch that I refer to as <em>‘Wekinator
FX Controller’</em>. It can be seen/heard in a couple of examples
here:</p>
<p><a href="https://vimeo.com/715768491/0c359471b3"
title="Video 3.1">Appendix A - Video 3.1: Wekinator with Voice
Sample</a></p>
<p><a href="https://vimeo.com/715955425/011dbe7187"
title="Video 3.2">Appendix A - Video 3.2: Wekinator with Wooden Recorder
Sample</a></p>
<p>(you can also have a look at the max patch in <a
href="#AppendixC"><strong>Appendix C: Patch 3</strong></a><a
href="#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a> and the Wekinator project file at
<a href="#AppendixD"><strong>Appendix D: Item 6</strong></a>)</p>
<p>With this interaction I tried to leverage the possibilities of
machine learning with Rebecca Fiebrink’s <strong>Wekinator</strong>
application<a href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a> in order to create more complex
parameter mappings for the interaction.</p>
<p>I wanted to focus on the <strong>mappings</strong> rather than
designing the effects themselves, so I decided to use MIDI to control an
existing plugin. I chose the Valhalla Frequency Echo plugin<a
href="#fn24" class="footnote-ref" id="fnref24"
role="doc-noteref"><sup>24</sup></a> as it has multiple parameters which
each have the ability to affect the sound output in relatively extreme
ways, relatively independent of each other. I also thought these
specific controls (delay length, shift amount, and feedback amount)
would be interesting as they have similar affects on the pitch of the
output sound, but through different techniques - I hoped this would
further <strong>confuse the user’s conceptual model</strong> of what
they were actually controlling in this interaction.</p>
<p>I used Wekinator to create a <strong>complex non-linear
mapping</strong> between the X, Y, and Z position of the left hand, and
the three chosen parameters of the plugin. I used looped audio samples
of my voice and a wooden recorder as the base for this interaction.</p>
<p>I hoped that the complex non-linear mappings of this interaction,
coupled with the complex extreme variation in the audio output would
result in a <strong>fun multiparametric interface</strong>.</p>
<p>(see <a href="#AppendixE6"><strong>Appendix E: Item 6</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-3"><strong>Results/Evaluation</strong></h3>
<p>I found this interaction joyful in how silly and ridiculous it felt.
The parameter mapping was so mysterious even to me as the designer that
it really encouraged a curious exploration of the interaction that
almost always resulted in a surprising output. This surprise was really
joyful.<a href="#fn25" class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a></p>
<p>I think it’s also worth noting that on reviewing the video
documentation of these interactions, this is the one that definitely
resulted in the most visible enjoyment in my physicality as I played
with it.</p>
<p>What stopped me from developing this interaction further was that it
felt slightly devoid of aesthetic meaning which left me slightly
underwhelmed. The output was surprising and playful, but the experience
as a whole lacked a sense of meaning. It felt like the be all and end
all of the interaction was to hear a sound warped in a chaotic way,
rather than having an overall aesthetic sensibility such as <em>playing
music</em> or <em>creating sci-fi sounds</em> or <em>trying to make
sad/happy/angry sounds</em>.</p>
<p>I would be interested in developing this interaction further in the
future as something that could work with real-time audio so that you
could for example use it to warp your voice or a musical performance
from another performer in real-time. I think this performative capacity
could be quite interesting and fun. <br><br></p>
<hr />
<h2 id="experiment-2.2---formant-filters">Experiment 2.2 - ‘Formant
Filters’</h2>
<h3 id="experimental-method-4"><strong>Experimental Method</strong></h3>
<p>This experiment exists as two prototypes. The first prototype can be
seen/heard here:</p>
<p><a href="https://vimeo.com/721082004/bf7c14dc24"
title="Video 5.1">Appendix A - Video 5.1: Formant Filters Prototype
#01</a></p>
<p>The second prototype can be seen/heard here:</p>
<p><a href="https://vimeo.com/731322891/f2340fc086"
title="Video 5.2">Appendix A - Video 5.2: Formant Filters Prototype
#02</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 9</strong></a>)</p>
<p>In this interaction I used <strong>formant filters</strong> to create
human <strong>speech-like synthesised sounds</strong>. I thought that
speech-like sound might encourage user engagement through the
<strong>perceived potential for expression</strong> (as human speech is
inherently very expressive). I also hoped that because speech is
something we are very used to forming subconsciously with our mouths,
the act of controlling it consciously with our hands would be a
<strong>fun challenge that subverts a familiar sonic
action</strong>.</p>
<p>During development I spent a lot of time trying and failing to get
the interaction to be capable of forming varied enough phonemes to form
words. Over time however I thought that this limitation of the system
not being able to approach speech in the way we normally would could be
a fun element of <strong>challenge</strong> where the goal of
comprehensible speech lies forever <em>just out of reach</em>.</p>
<p>The first prototype was an attempt to make the general interaction as
simple as possible, focusing on the <strong>complexity of the sonic
output</strong> and the vowel system as a control method instead.</p>
<p>The second prototype was an experiment in designing a
<strong>complicated control interface</strong> that used a somewhat
unusual combination of fast movement triggers, hand position, and hand
shape. I thought perhaps using a <strong>range of different
controls</strong> would make for a satisfying experience.</p>
<p>I was also trying to use the envelope system to add a sense of
changing inflection to further create the sense of possible meaningful
expression lying just out of reach of the user.</p>
<p>(see <a href="#AppendixE7"><strong>Appendix E: Item 7</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-4"><strong>Results/Evaluation</strong></h3>
<p>I shared the first prototype of this interaction during the Future
Flavours of Sound Festival 2022, and got some positive feedback from the
panellists who really enjoyed the vowel sounds as a playful output:</p>
<blockquote>
<p>“…the vowel thing, that was fucking awesome… that was something I had
not expected at all.” - Yann Seznec<a href="#fn26" class="footnote-ref"
id="fnref26" role="doc-noteref"><sup>26</sup></a></p>
</blockquote>
<p>This definitely suggests that there is joyful potential with this
interaction. Specifically I think the <strong>surprise</strong>
expressed here speaks to the joy in controlling something like audible
speech with your hands instead of your mouth. This <strong>subversion of
expectation</strong> seems really enjoyable for people.</p>
<p>The second prototype however, feels less joyful. In the play testing
feedback below, users said that they “like and dislike how difficult it
is.” This suggests potential for joy in the challenge, but judging by
the fact that of the 5 interactions tested by these participants, for
both users this one was one of the ones they spent the least time with,
it seems that in it’s current state the complexity of this interaction
makes it more <strong>frustrating</strong>.</p>
<p>I also personally feel that there is slightly too much
<strong>chaos</strong> in the latest prototype of this interaction and
that maybe something was lost when actions such as the velocity based
trigger were added in. This trigger system whilst fun in some scenarios
because of the energy required, feels so <strong>aesthetically
dissonant</strong> from how you would expect to be making the sounds
that you’re hearing that I think it makes the experience much more
<strong>confused</strong> and less fun.</p>
<h4 id="play-testing-documentation101-1"><strong>Play Testing
Documentation</strong><a href="#fn27" class="footnote-ref" id="fnref27"
role="doc-noteref"><sup>27</sup></a></h4>
<p>This was an experiment that I managed to user test with two
participants. Here are some quotes they gave during our discussions that
I found particularly insightful:</p>
<blockquote>
<p>“Cacophonous” - Andrew</p>
</blockquote>
<blockquote>
<p>“It takes a lot of effort” - Andrew</p>
</blockquote>
<blockquote>
<p>“I really like and dislike how difficult it is to control the vowels”
- Andrew</p>
</blockquote>
<blockquote>
<p>“like [your hands] are going against each other rather than working
together” - Andrew</p>
</blockquote>
<blockquote>
<p>“I found this a little bit more confusing compared to the other ones
because it took a lot more getting used to the controls to be able to
make specific sounds.” - Lyla</p>
</blockquote>
<blockquote>
<p>“it feels more complicated compared to the other ones… not because of
what’s there but because of what I’m having to do with my hands” -
Lyla</p>
</blockquote>
<blockquote>
<p>“the association I had with [the sound] felt more personal because
it’s closer to a human voice, so in that sense the tool felt easier for
me to understand in terms of like conceptually what it is but in terms
of like how to control it, it took more effort.” - Lyla</p>
</blockquote>
<p><em>(more extensive lists of written quotes taken from these
discussions can be found in</em> <a
href="#AppendixF1"><strong><em>Appendix F: Item
1</em></strong></a><em>)</em></p>
<p>User play testing videos of this interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/741239191/c737ddd211"
title="Video 5.3">Appendix A - Video 5.3: Formant Filter Play Test -
Andrew</a></p>
<p><a href="https://vimeo.com/741240744/4c644af02c"
title="Video 5.4">Appendix A - Video 5.4: Formant Filter Play Test -
Lyla</a></p>
<p>The full audio interviews with Andrew and Lyla just after they had
each experienced this interaction can be heard here:</p>
<p><a href="https://on.soundcloud.com/GrZ4">Appendix B - Audio 1.3:
Andrew Play Test Interview - Formant Filters</a></p>
<p><a href="https://on.soundcloud.com/QuyP">Appendix B - Audio 2.3: Lyla
Play Test Interview - Formant Filters</a> <br></p>
<hr />
<h2 id="experiment-2.3---concatenative-corpus-explorer">Experiment 2.3 -
‘Concatenative Corpus Explorer’</h2>
<h3 id="experimental-method-5"><strong>Experimental Method</strong></h3>
<p>For this experiment I developed a patch I refer to as
<em>‘Concatenative Corpus Explorer’</em> which can be seen/heard
here:</p>
<p><a href="https://vimeo.com/738253819/8dabc44794"
title="Video 6.3">Video 6.3: Concatenative Corpus Explorer Prototype
#02</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 5</strong></a>)</p>
<p>This patch was largely adapted from James Bradbury’s 2D Corpus
Explorer<a href="#fn28" class="footnote-ref" id="fnref28"
role="doc-noteref"><sup>28</sup></a>, made with the FluCoMa toolkit.</p>
<p>For this experiment I wanted to explore more ways to create a
<strong>complex non-linear sonic output</strong>. I was particularly
drawn to the concatenative possibilities of the FluCoMa toolkit because
of the quick customisation possibilities of changing the target corpus
in order to completely change the sound of the interaction. This variety
felt like it spoke to the <strong>open-endedness</strong> I was aiming
for in these experiments. In the current patch I include 3 corpuses that
have contrasting sonic textures to try to achieve this
open-endedness.</p>
<p>I hoped that this interaction would be <strong>joyful in how complex
the output sound is</strong>. Even though the controls are relatively
simple action wise, the movement through the corpus results in such
<strong>unpredictable changes in pitch, loudness, and timbre</strong>
that it is still difficult to control the sound output in an intentional
way. I hoped that the complex sonic output would give the
<strong>illusion of expressive control</strong> even when used naively,
and would therefore encourage users to continue using the interaction to
try to gain even more control over the chaotic sound.</p>
<p>(see <a href="#AppendixE8"><strong>Appendix E: Item 8</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-5"><strong>Results/Evaluation</strong></h3>
<p>I personally think this is one of my two favourites of all of the
interactions. I think <strong>for me the joy comes from the sensation of
controlling such a complex sound</strong>. Even though I don’t
<em>need</em> to make complex intricate motions with my hands to create
the sound, I found that the complexity of the sound made me want to move
in a way that sort of mimicked the sound movement which then made the
whole experience feel very satisfying.</p>
<p>I particularly felt that the delay line control made a big
difference, as the slight pitch shift it caused when fluttering the left
hand fingers gave <strong>the illusion of more control than you actually
have</strong> because the sound responds to movements as intricate as
finger movements.</p>
<p>I also personally really enjoyed the volume being controlled by the
fist opening and closing, as this made it feel more <strong>possible to
create varying phrases</strong> with the sound. The detail of the fist
opening meant that volume could still be controlled quite carefully, but
also could be sustained or stopped at any time very easily. I think this
was especially possible because the right hand had only the two simple
controls, and so didn’t need to do any other complex movements that
would interfere with opening and closing the fist.</p>
<p>This interaction also resulted in some really positive responses from
users who tested it, as is recorded below. Users in particular seemed to
really like <strong>the challenge of trying to control the complex
sound</strong>, and the <strong>responsive simplicity of the low-pass
filter</strong>.</p>
<h4 id="play-testing-documentation101-2"><strong>Play Testing
Documentation</strong><a href="#fn29" class="footnote-ref" id="fnref29"
role="doc-noteref"><sup>29</sup></a></h4>
<p>This was an experiment that I managed to user test with two
participants. Here are some quotes they gave during our discussions that
I found particularly insightful:</p>
<blockquote>
<p>“I think I just made the coolest piece… this one might actually be my
favourite so far out of all of them…” - Andrew</p>
</blockquote>
<blockquote>
<p>“what’s nice about it is how it’s limiting, you can’t just [go to the
point you want]” - Andrew</p>
</blockquote>
<blockquote>
<p>“it’s slightly annoying that you can’t just pick exactly where it is
[the position that determines the playback slice of audio] but also
that’s like kind of one of my favourite parts about it” - Andrew</p>
</blockquote>
<blockquote>
<p>“it feels less like an audio tool… I would say this one feels more
playful” - Andrew</p>
</blockquote>
<blockquote>
<p>“I’m a very big fan… I really enjoyed it” - Lyla</p>
</blockquote>
<blockquote>
<p>“I love the filter… it was very consistent throughout all of the
settings and… the freedom that I had and the sensitivity, it works well
with the sensor - I felt like it was easier to control in this one” -
Lyla</p>
</blockquote>
<blockquote>
<p>“it felt more like I was playing with it this time compared to the
other ones” - Lyla</p>
</blockquote>
<p><em>(more extensive lists of written quotes taken from these
discussions can be found in</em> <a
href="#AppendixF1"><strong><em>Appendix F: Item
1</em></strong></a><em>)</em></p>
<p>User play testing videos of this interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/741239049/a9e4be97fc"
title="Video 6.4">Appendix A - Video 6.4: Concatenative Play Test -
Andrew</a></p>
<p><a href="https://vimeo.com/741240646/8e1af7fa71"
title="Video 6.5">Appendix A - Video 6.5: Concatenative Play Test -
Lyla</a></p>
<p>The full audio interviews with Andrew and Lyla just after they had
each experienced this interaction can be heard here:</p>
<p><a href="https://on.soundcloud.com/yN6t">Appendix B - Audio 1.4:
Andrew Play Test Interview - Concatenative</a></p>
<p><a href="https://on.soundcloud.com/TVQD">Appendix B - Audio 2.4: Lyla
Play Test Interview - Concatenative</a></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="chapter-3-joy-through-the-embodied">Chapter 3: Joy Through the
Embodied</h1>
<h2 id="theory---embodied-sonic-interactions-and-instruments">Theory -
Embodied Sonic Interactions and Instruments</h2>
<p>My third approach to joy within physical sound interactions focuses
on the concept of <strong>embodied interactions</strong>. Atau Tanaka
uses the term “Embodied Sonic Interaction”<a href="#fn30"
class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a>
in a talk by the same name at The New School in 2013, in which he brings
attention to the definition of <strong>embody</strong> as a verb:</p>
<blockquote>
<p>“To give tangible, bodily, or concrete form to (an abstract concept)”
or “To collect or unite in a comprehensive whole, system, etc.” <a
href="#fn31" class="footnote-ref" id="fnref31"
role="doc-noteref"><sup>31</sup></a></p>
</blockquote>
<p>Tanaka notes that this ‘abstract concept’ might be an idea, quality,
or feeling. The sense of <strong>uniting</strong> into a single whole
speaks to me of <strong>the ideal that the act design aims
for</strong>.</p>
<p>These ideas of embodied interactions build upon research by Fishkin
et al. on what they refer to as <strong>“Embodied User
Interfaces,”</strong> which require that “…the manipulation
[<strong>input</strong>] and the virtual representation
[<strong>output</strong>] are <strong>integrated within the same
object</strong>,”<a href="#fn32" class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a> (the object here being the
interface). Fishkin et al. describe these embodied user interfaces as
being “…on an evolutionary path towards <strong>an ideal of the
invisible user interface</strong>.”<a href="#fn33" class="footnote-ref"
id="fnref33" role="doc-noteref"><sup>33</sup></a></p>
<p>The <strong>close-ness</strong> described by this concept of an
embodied interface or interaction suggests joy to me. It makes me think
of interactions in everyday life where the object or interface used
<strong>feels so connected to the task that it fulfils that we hardly
notice it</strong> (for example a kettle or a kitchen tap).</p>
<p>Ge Wang addresses this concept of embodiment in his <em>‘Artful
Design’</em>:</p>
<blockquote>
<p>“We humans are <strong>embodied</strong> creatures; we operate more
efficiently, satisfyingly when we ‘<strong>feel as one</strong>’ with
the interface we are using! Similar to using our hands, an embodied
interface allows us to think less about how to control it and more about
what we’d want to <strong>do</strong> with it..” <a href="#fn34"
class="footnote-ref" id="fnref34"
role="doc-noteref"><sup>34</sup></a></p>
</blockquote>
<blockquote>
<p>“…the most effective and elegant interactions are the result of
interfaces that mediate and seamlessly bind the user and artefact into a
<strong>single system</strong>.” <a href="#fn35" class="footnote-ref"
id="fnref35" role="doc-noteref"><sup>35</sup></a></p>
</blockquote>
<p>I find Wang’s description of the merits of this embodiment really
inspiring. The interactions he describes feel as if they offer a
<strong>freedom of expression and control</strong> that is truly ideal:
more <strong>organic</strong> and <strong>biological</strong> than the
logical interactions we might expect to have with a computer. These
kinds of interactions where the technology aims to
“<strong>extend</strong> us – our bodies and even our intentions…”<a
href="#fn36" class="footnote-ref" id="fnref36"
role="doc-noteref"><sup>36</sup></a> feel truly joyful to me. Because
these embodied interactions focus on extending <strong>us</strong> as a
user, the impressive outputs possible from the interaction become more
personally internalised. Instead of thinking <em>‘Wow! How awesome that
this synth can make that sound!’</em>, we might think <em>’Wow! How
awesome that</em> <strong><em>I</em></strong> <em>can make that
sound!’</em>. To me, this distinction is hugely significant and brings
with it a lot joy and fun.</p>
<p>This <strong>joy through the personal</strong> is something that was
also brought to my attention during discussion that I had with Sandra
Pauletto during the ‘Sound Design(ed) Futures’ Conference, hosted by the
Université Gustave Eiffel.<a href="#fn37" class="footnote-ref"
id="fnref37" role="doc-noteref"><sup>37</sup></a> I asked the speakers
about their thoughts on <strong>‘fun’ within sonic interactions</strong>
in relation to their own work with physical sound interactions, and
Pauletto spoke specifically on how <strong><em>personal
experience</em></strong> was something that she actively thought about
when <strong>designing enjoyable interactions</strong> for users.
Personal experience, Pauletto posited, allows for a wide range of users
who will likely have varying tastes and preferences to bring in their
own desires into an interaction.<a href="#fn38" class="footnote-ref"
id="fnref38" role="doc-noteref"><sup>38</sup></a></p>
<p>From these concepts of embodied interactions, I derived the following
design principles to investigate in my own interactions:</p>
<ul>
<li>design for an <strong><em>aesthetic coherence</em></strong> between
the <strong>input</strong> and <strong>output</strong></li>
<li>make the interface feel <strong>invisible</strong></li>
<li>conceptualise the interaction as an <strong><em>extension of the
body/hands</em></strong> rather than a separate entity</li>
</ul>
<p>These next three experiments demonstrate a few attempts at using this
<em>embodied</em> framework to investigate joy in physical sound
interactions. <br><br></p>
<hr />
<h2 id="experiment-3.1---fm-velocity-synth">Experiment 3.1 - ‘FM
Velocity Synth’</h2>
<h3 id="experimental-method-6"><strong>Experimental Method</strong></h3>
<p>For this interaction, I designed an interaction that I refer to as
<em>‘FM Velocity Synth’</em>. This interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/719826180/035ab5f274"
title="Video 4.7">Appendix A - Video 4.7: FM Synth Prototype #03</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 2</strong></a>)</p>
<p>In this interaction I tried to focus on <strong>making the sound
output as descriptive of the input action as possible</strong>. I was
imagining what I would want it to sound like if I was creating a sound
design to describe the action of moving my hand. By focusing in this way
I was hoping to <strong>make the interface as invisible as
possible</strong>, where moving the hands didn’t feel like an act of
changing parameters, but instead <strong>as you move the hand the
parameters change such that the sound feels like it
accompanies/underscores the action appropriately</strong>.</p>
<p>One of the main ways that I tried to achieve this was by
<strong>mapping the volume of the synth to the velocity of the
hand</strong>. By doing this, I aimed to connect the energy of the input
as closely as possible to the energy of the output. In my mind this
matching would give not only <strong>aesthetic coherence</strong> to the
interaction (both input and output <em>behave</em> similarly) but also
it would perhaps suggest a more invisible interface through the apparent
<strong>conservation of energy</strong>. By conservation of energy I
refer to the physical law that the energy put <em>into</em> a system
must always equal the energy expelled <em>out</em> of it. This universal
truth is usually pretty effectively governed by the laws of physics,
however in the world of digital musical interfaces it is easy to bypass
this rule as energy provided by the technology can be used to create
output even if there is ‘no’ input present (for example in my
experiments 2.1 or prototype 1 of experiment 2.2, where volume is
constant throughout the interaction even if the hand is still or not
present). Therefore, I hoped that <strong>by making this interaction
(apparently) ‘obey’ this law of physics, it would be perceived more as a
‘real’ interaction rather than a digitally mediated interaction only
made possible by intervening technology</strong>.</p>
<p>I also aimed to create the sense of the interaction <strong>extending
the body</strong> by trying to dictate my design through
<strong>physical logic</strong> such as:</p>
<ul>
<li>each hand is <strong>distinct</strong>, so it should control a
distinct synth voice</li>
<li>both hands are physically <strong>similar</strong> so they should
have a <strong>similar ‘hand’ sound</strong> but with small variations
to distinguish one from the other</li>
<li>an open hand <strong>feels different</strong> to a closed fist, so
it should have a <strong>different sound</strong> and should sound
‘muffled’ as if the sound coming from the hand is being blocked by it
being closed</li>
</ul>
<p>(see <a href="#AppendixE9"><strong>Appendix E: Item 9</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-6"><strong>Results/Evaluation</strong></h3>
<p>I shared a video of this interaction during the Future Flavours of
Sound Festival 2022, and got some positive feedback from the panellist
Yann Seznec who really enjoyed the <strong>control of the volume and
filtering</strong>:</p>
<blockquote>
<p>“oh man, it’s really nice that it’s like, I guess, velocity based?
…it’s amazing how simple that feels, and yet it’s very effective because
it means you can hold your hands still and there’s no sound and that’s a
very strong sonic interaction kind of thing was actually managing
silence. Because managing silence in anything that involves movement is
very hard - especially anything that involves direct mapping of
movement… so that I thought was really effective.” - Yann Seznec<a
href="#fn39" class="footnote-ref" id="fnref39"
role="doc-noteref"><sup>39</sup></a></p>
</blockquote>
<blockquote>
<p>“Leaning into [fist opening and closing] was a good choice because
from a sound design perspective and a sound interaction perspective,
closing your hand for me definitely has that kind of filtering feel… it
works - that connection is very strong… you don’t even notice it
happening because it’s such a strong interaction.” - Yann Seznec<a
href="#fn40" class="footnote-ref" id="fnref40"
role="doc-noteref"><sup>40</sup></a></p>
</blockquote>
<p>Personally I was really happy with this interaction from a technical
standpoint, but <strong>I wouldn’t describe it as joyful</strong> for
myself. It feels <strong>satisfying</strong> in how closely it describes
my actions, but I think it is also limited by this close description. In
my mind, <strong>the interaction translates the hands actions in a
satisfying way, but doesn’t extend them enough to be fun</strong> in a
way that would make me want to spend a long time with this
interaction.</p>
<p>I do feel that the volume control with velocity is very satisfying,
and for me really successfully gives the impression of an
‘<strong>invisible interface</strong>’. I would be interested in taking
this aspect of the interaction and experimenting with it further on
different sounds. <br><br></p>
<hr />
<h2 id="experiment-3.2---scrubber-explorer">Experiment 3.2 - ‘Scrubber
Explorer’</h2>
<h3 id="experimental-method-7"><strong>Experimental Method</strong></h3>
<p>For this interaction, I designed an interaction that I refer to as
<em>‘Scrubber Explorer’</em>. This interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/738243186/a9243c39a8"
title="Video 10.2">Appendix A - Video 10.2: Scrubber Explorer Prototype
#02</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 7</strong></a>)</p>
<p>This experiment came about somewhat unexpectedly when I was playing
with an earlier interaction that I designed to emulate record
scratching, which you can see/hear here:</p>
<p><a href="https://vimeo.com/732201910/109f9a3602"
title="Video 9.2">Appendix A - Video 9.2: Record Scratching
Simulator</a></p>
<p>This interaction mimicked the action of <strong>stopping a record on
a turntable and scratching it</strong> back and forth. However, when I
was playing with it I noticed that sometimes when moving my hand very
slowly the low-pitched sound that resulted (from the audio playing back
at an extremely slow playback rate) felt very <strong>descriptive of the
movement of my hand</strong>.</p>
<p>I decided to therefore create this explorer interaction where,
similar to experiment 3.1, the sound is driven by the velocity of your
hand, except in this interaction it controls the sound via playback rate
rather than volume. This is an interesting relationship as <strong>there
is something quite ‘natural’ in the connection of hand speed to playback
rate - as the playback rate is effectively the speed of the
sound</strong>. I hoped that this connection would make the interaction
feel like a more <strong>embodied experience</strong>.</p>
<p>(see <a href="#AppendixE10"><strong>Appendix E: Item 10</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-7"><strong>Results/Evaluation</strong></h3>
<p>As a designer, this interaction is probably <strong>my
favourite</strong> of all of the ones I have made for this project. The
(relative) <strong>technical simplicity</strong> of it feels incredibly
satisfying, <strong>knowing that the huge range of sound quality that I
am getting from the experience is largely down to a single playback rate
control system</strong>. I also think aesthetically there is something
very pleasing about being able to ‘<strong>explore</strong>’ a single
moment in an audio buffer so <strong>physically</strong> with your
hands, and in doing so hear a sound that might be familiar in a new
unfamiliar way.</p>
<p>I do feel that the <strong>connection of my physical energy to the
playback rate makes this interaction feel like an extension of my body
in a very satisfying way that also makes me less aware of the
interface</strong>. I do think it’s a shame that this interaction has so
many interface controls that are set and changed in max MSP with the
mouse, which obviously <strong>breaks this sense of there being no
interface</strong> - but for me the variety that this offers is worth
the possible loss of immersion.</p>
<p>I also really enjoy how <strong>physical</strong> the sound output
feels in this interaction. Depending on the sound used, it really sounds
like your hands are <strong>moving through different mediums like paper
or mud</strong>. I think that the apparent physicality of this
interaction makes it feel like you have a lot <strong>more control over
the sound than you technically do</strong>, and this makes for a really
<strong>enjoyable</strong> experience.</p>
<p>The users who play tested this interaction enjoyed it as well as I
have recorded below. I found it particularly interesting how Lyla
commented that she felt she “<strong>needed to create the sound
myself</strong>,” and that Andrew felt with some sounds that he was
controlling “<strong>every little particle that happens within the
sound</strong>.” I think these comments support the idea that the
<strong>embodied control</strong> I tried to achieve with this design
gives a <strong>joyful</strong> sense of control.</p>
<h4 id="play-testing-documentation101-3"><strong>Play Testing
Documentation</strong><a href="#fn41" class="footnote-ref" id="fnref41"
role="doc-noteref"><sup>41</sup></a></h4>
<p>This was an experiment that I managed to user test with two
participants. Here are some quotes they gave during our discussions that
I found particularly insightful:</p>
<blockquote>
<p>“I feel like you’re allowed to be really creative while you’re
playing with [the interaction] because there are so many options.” -
Andrew</p>
</blockquote>
<blockquote>
<p>“I really liked being able to find a specific part of the audio file
that you could then control… then that being randomised I feel like
keeps things really interesting and really fresh each time you start
moving around because its like really playful.” - Andrew</p>
</blockquote>
<blockquote>
<p>“It definitely reminds me of like playing with records and like
trying to figure how to do live scratching with records which is always
super fun” - Andrew</p>
</blockquote>
<blockquote>
<p>“The singing bowl one on its own I feel like is not as fun to mess
with because it’s such a constant sound… but the plastic bag and the
paper tearing because they’re so like textural… it makes you feel like
you’re really controlling every little particle that happens within the
sound which is really fun” - Andrew</p>
</blockquote>
<blockquote>
<p>“it’s kind of like an investigation” - Lyla</p>
</blockquote>
<blockquote>
<p>“it was really cool to sometimes combine [the sounds]” - Lyla</p>
</blockquote>
<blockquote>
<p>“consistency was one thing I wasn’t like very comfortable with… but
that’s what I kind of like about it too, it kind of breaks your
expectations” - Lyla</p>
</blockquote>
<blockquote>
<p>“when I was doing it I didn’t feel like I was just pressing buttons
to get a sound… I needed to create the sound myself so I needed to
figure it out and get familiar with it” - Lyla</p>
</blockquote>
<p><em>(more extensive lists of written quotes taken from these
discussions can be found in</em> <a
href="#AppendixF1"><strong><em>Appendix F: Item
1</em></strong></a><em>)</em></p>
<p>User play testing videos of this interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/741239369/da15dd0b82"
title="Video 10.3">Appendix A - Video 10.3: Scrubber Explorer Play Test
- Andrew</a></p>
<p><a href="https://vimeo.com/741240938/0f6ec0dc15"
title="Video 10.4">Appendix A - Video 10.4: Scrubber Explorer Play Test
- Lyla</a></p>
<p>The full audio interviews with Andrew and Lyla just after they had
each experienced this interaction can be heard here:</p>
<p><a href="https://on.soundcloud.com/BsMh">Appendix B - Audio 1.1:
Andrew Play Test Interview - Scrubber Explorer</a></p>
<p><a href="https://on.soundcloud.com/AD2E">Appendix B - Audio 2.1: Lyla
Play Test Interview - Scrubber Explorer</a></p>
<hr />
<h2 id="experiment-3.3---magic-spells">Experiment 3.3 - ‘Magic
Spells’</h2>
<h3 id="experimental-method-8"><strong>Experimental Method</strong></h3>
<p>For this experiment I designed an interaction that I refer to as
<em>‘Magic Spells’</em> which can be seen/heard here:</p>
<p><a href="https://vimeo.com/738304157/e439f2bdd8"
title="Video 11.3">Video 11.3: Magic Spells Prototype #03</a></p>
<p>(you can also have a look at the max patch - <em>or even try it out
if you have a LeapMotion camera!</em> - in <a
href="#AppendixC"><strong>Appendix C: Patch 10</strong></a>)</p>
<p>With this interaction I was aiming to use a
<strong>combination</strong> of synthesis techniques from previous
experiments and use them to create an interaction that was
<strong>strictly representing a single fantastical action</strong>. This
fantastical action being <strong>casting magic spells</strong>. This
felt like a <strong>fun</strong> interaction to design for as it is a
commonly understood action with some <strong>recognisable associated
actions</strong>, whilst still being something completely fantastical
that <strong>cannot actually be achieved without some kind of extension
of our own bodies</strong>.</p>
<p>I conceptualised the physical action of casting a spell as first
holding your hand closed in a fist to start <strong>charging</strong> up
magical energy, and then opening your hand fully to
<strong>release</strong> the energy as a magical spell that shoots out
from your hand. This felt like it had a fairly appropriate basis in
depictions of magic in pop culture, whilst also feeling <strong>clearly
defined</strong> enough to be recognised by the LeapMotion.</p>
<p>By <strong>focusing on a single action</strong> (casting a spell), I
hoped that the user would <strong>conceptualise this interaction more as
an embodied experience, rather than as an abstract tool to control
sound</strong> (which suggests more of a separation between the user and
the sonic output).</p>
<p>(see <a href="#AppendixE11"><strong>Appendix E: Item 11</strong></a>
for more technical details of this experiment)</p>
<h3 id="resultsevaluation-8"><strong>Results/Evaluation</strong></h3>
<p>I think this is a really <strong>joyful</strong> interaction. I also
think that the joy I get from this interaction is really distinctively
<strong>playful</strong>. Whilst some of my other favourite interactions
are joyful because they feel like such a complex way of controlling
sound, this one is one of my favourites because <strong>it feels so fun
to pretend to be able to cast spells</strong> - and I think the
interaction does a pretty good job of creating this sonic illusion.</p>
<p>The camera sometimes losing track of the hands does make the
<strong>limitation of the interaction space quite apparent</strong>, but
at worse I think this makes the interaction feel like <strong>a game
that is really fun when you play successfully, and mildly infuriating
when you fail</strong> - a hallmark of many games that I truly
enjoy.</p>
<p>Even in this relatively basic state I think this interaction shows
real promise for creating a really joyful embodied interaction that
could speak to a fairly universal concept of playful fun where we can
pretend to have magical super powers.</p>
<p>The play testers for this interaction also seemed to enjoy this
interaction - with Andrew going so far as to call it “<strong>the most
fun out of all of them</strong>”.</p>
<p>I definitely plan to develop this interaction further, potentially
find way to further <strong>customise</strong> the spell being cast by a
hand, or experimenting with <strong>different sounds</strong> to see how
they change the <strong>embodied sensation</strong> of the
interaction.</p>
<h4 id="play-testing-documentation101-4"><strong>Play Testing
Documentation</strong><a href="#fn42" class="footnote-ref" id="fnref42"
role="doc-noteref"><sup>42</sup></a></h4>
<p>This was an experiment that I managed to user test with two
participants. Here are some quotes they gave during our discussions that
I found particularly insightful:</p>
<blockquote>
<p>“this one’s definitely I think the most fun out of all of them… I
don’t know if it’s my favourite one but I think it’s the most playful
one for sure” - Andrew</p>
</blockquote>
<blockquote>
<p>“I feel like the controls in this one are simpler than the others… it
has very few things that you can tell that you’re controlling at least,
regardless of how many things are going on under the surface” -
Andrew</p>
</blockquote>
<blockquote>
<p>“it really feels like you have this power in your hands now through
this one” - Andrew</p>
</blockquote>
<blockquote>
<p>“it’s playing around with like the anticipation of a sound or like
the result that you expect” - Lyla</p>
</blockquote>
<blockquote>
<p>“I was slightly annoyed by how the sensor did not always pick up what
I was doing with my hands… I also felt like I wanted to have the freedom
to orchestrate the charging speed of the respective batteries, which was
not available. However, it was cool to notice the change in my emotional
response to these issues over time, as I was able to positively accredit
the subtle frustration for making the interaction feel more game-like,
eventually sparking a very different sense of joy.” - Lyla</p>
</blockquote>
<p><em>(more extensive lists of written quotes taken from these
discussions can be found in</em> <a
href="#AppendixF1"><strong><em>Appendix F: Item
1</em></strong></a><em>)</em></p>
<p>User play testing videos of this interaction can be seen/heard
here:</p>
<p><a href="https://vimeo.com/741239231/16039d8ebd"
title="Video 11.4">Appendix A - Video 11.4: Magic Spells Play Test -
Andrew</a></p>
<p><a href="https://vimeo.com/741240846/47ce7435a2"
title="Video 11.5">Appendix A - Video 11.5: Magic Spells Play Test -
Lyla</a></p>
<p>The full audio interviews with Andrew and Lyla just after they had
each experienced this interaction can be heard here:</p>
<p><a href="https://on.soundcloud.com/7asP">Appendix B - Audio 1.5:
Andrew Play Test Interview - Magic Spells</a></p>
<p><a href="https://on.soundcloud.com/sXxJ">Appendix B - Audio 2.5: Lyla
Play Test Interview - Magic Spells</a></p>
<p><em>(N.B. this audio interview with Lyla [Audio 2.5] was
unfortunately cut off by a recording device malfunction - Lyla kindly
wrote up some of her thoughts on this interaction which you can find
fully in</em> <strong><em>Appendix F, Section 1</em></strong>
<em>)</em></p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="conclusion">Conclusion</h1>
<p>To conclude what I’ve learnt from this project and the experiments
within, I have gained insight into what makes physical sound
interactions joyful to me as a designer and user. I summarise these
as:</p>
<ul>
<li><p><strong><em>Responsive systems are joyful</em></strong></p></li>
<li><p><strong><em>Direct mapping of energy in the input to energy in
the output is joyful</em></strong></p></li>
<li><p><strong><em>The ability to construct/sculpt phrases is
joyful</em></strong></p></li>
<li><p><strong><em>Aesthetic connection between input and output is
joyful</em></strong></p></li>
</ul>
<p>There were many other insights into physical sound interactions that
I gained, as documented in the experimental evaluations in this write
up, but for me these points above stood out as pivotal ideas that
persisted in my mind throughout these different experiments. These ideas
helped me grasp the ways that I experience joy within these
interactions.</p>
<p>Joy is undoubtedly a subjective experience that will mean different
things for different people at different points in their lives, which is
exactly why for me as a designer it is so useful to take this research
opportunity to break it down a bit and analyse personally <strong>what
joy means to me</strong> <strong><em>now</em></strong> within these
interactions. Having made these conclusions, I look forward to taking
these concepts into my future design work and seeing how my
understanding and experience of them changes over time.</p>
<p>I think it was always an over-ambitious goal to capture the essence
of joy in a way that could be easily identified and ‘bottled’ for easy
access and liberal future application. However, this project has been an
excellent exercise in taking an <strong>emotional</strong> and
<strong>experiential</strong> end goal, exploring and experimenting the
many ways in which I might achieve it <strong>technically</strong> and
<strong>aesthetically</strong>, and evaluating why they do and don’t
work (<em>for me</em> and possibly for others).</p>
<h2 id="the-future-of-this-project"><strong>The Future of this
Project</strong></h2>
<p>This project has happily presented many new questions and paths along
the way for me that have either been beyond the scope of this specific
project, or that I haven’t had the time to properly pursue and
integrate. In the future I hope to develop this project into a more
accessible compact software that I can share online, conduct larger
participant studies for feedback, and go further in depth into the
possibilities of using these interactions in my own artistic practice in
either a live performance or installation context.</p>
<p>For further details on these conclusions, my role within the project,
and the failures and future directions of this project see
<strong>Appendix E Items <a href="#AppendixE12">12</a>, <a
href="#AppendixE13">13</a>, <a href="#AppendixE14">14</a> and <a
href="#AppendixE15">15</a></strong>.</p>
<p><br><br></p>
<hr />
<p><br><br></p>
<h1 id="bibliography">Bibliography</h1>
<p>Abstract: The Art of Design. ‘Cas Holman: Design For Play’. Publikro
London, RadicalMedia, Tremolo Productions, 21 January 2017. <br> <br>
Ashanti, Onyx. ‘Onyx Ashanti | Speaker | TED’. Accessed 22 August 2022.
<a
href="https://www.ted.com/speakers/onyx_ashanti">https://www.ted.com/speakers/onyx_ashanti</a>.
<br> <br> Bradbury, James. ‘Learn FluCoMa: 2D Corpus Explorer’. Accessed
1 August 2022. <a
href="https://learn.flucoma.org/learn/2d-corpus-explorer/">https://learn.flucoma.org/learn/2d-corpus-explorer/</a>.
<br> <br> Cardiff, Janet. ‘The Missing Voice (Case Study B) | Artangel’.
Accessed 22 August 2022. <a
href="https://www.artangel.org.uk/project/the-missing-voice-case-study-b/">https://www.artangel.org.uk/project/the-missing-voice-case-study-b/</a>.
<br> <br> Collins English Dictionary – Complete and Unabridged. 12th
Edition., 2014. <a
href="https://www.thefreedictionary.com/embody">https://www.thefreedictionary.com/embody</a>.
<br> <br> Fiebrink, Rebecca. ‘Wekinator | Software for Real-Time,
Interactive Machine Learning’. Accessed 22 August 2022. http://<a
href="www.wekinator.org/">www.wekinator.org/</a>. <br> <br> Fishkin et
al. ‘Embodied User Interfaces: Towards Invisible User Interfaces |
SpringerLink’. Accessed 8 August 2022. <a
href="https://link.springer.com/chapter/10.1007/978-0-387-35349-4_1">https://link.springer.com/chapter/10.1007/978-0-387-35349-4_1</a>.
<br> <br> Future Flavours of Sound Festival 2022 - Audio Programming and
Technologies, 2022. <a
href="https://www.youtube.com/watch?v=iCKRifnjdDA">https://www.youtube.com/watch?v=iCKRifnjdDA</a>.
<br> <br> Goldsmiths, University of London. ‘Prof Atau Tanaka’. Accessed
22 August 2022. <a
href="https://www.gold.ac.uk/computing/people/tanaka-atau/">https://www.gold.ac.uk/computing/people/tanaka-atau/</a>.
<br> <br> Hunt, Andy, and Ross Kirk. ‘Mapping Strategies for Musical
Performance’, 2000, 28. <br> <br> McCausland, Douglas. ‘Douglas
McCausland // Official Website’. Accessed 22 August 2022. <a
href="https://www.douglas-mccausland.net">https://www.douglas-mccausland.net</a>.
<br> <br> ‘Michel Waisvisz – DIGITAL ART (1960-2000)’. Accessed 22
August 2022. <a
href="https://www.digitalcanon.nl/?artworks=michel-waisvisz">https://www.digitalcanon.nl/?artworks=michel-waisvisz</a>.
<br> <br> ‘MiMU | Home’. Accessed 22 August 2022. <a
href="https://mimugloves.com/">https://mimugloves.com/</a>. <br> <br>
Norman, Donald A. The Design of Everyday Things / Donald A. Norman.
Revised and Expanded edition. Cambridge, Massachusetts: The MIT Press,
2013. <br> <br> ‘Punchdrunk “The World’s Leading Immersive Theatre
Company” – GQ Magazine’. Accessed 22 August 2022. <a
href="https://www.punchdrunk.com/">https://www.punchdrunk.com/</a>. <br>
<br> ‘Sound Design(ed) Futures : New realities, spaces, technologies’.
Accessed 27 May 2022. <a
href="https://lisaa.univ-gustave-eiffel.fr/actualites/actualite/sound-designed-futures-new-realities-spaces-technologies">https://lisaa.univ-gustave-eiffel.fr/actualites/actualite/sound-designed-futures-new-realities-spaces-technologies</a>.
<br> <br> Tanaka, Atau. Embodied Sonic Interaction: Gesture, Sound and
the Everyday, 2013. <a
href="https://www.youtube.com/watch?v=IyOUVixqmTU">https://www.youtube.com/watch?v=IyOUVixqmTU</a>.
<br> <br> Valhalla DSP. ‘Valhalla Freq Echo: Freqency Shifter Plugin |
Free Reverb Plugin’. Accessed 22 August 2022. <a
href="https://valhalladsp.com/shop/delay/valhalla-freq-echo/">https://valhalladsp.com/shop/delay/valhalla-freq-echo/</a>.
<br> <br> Wang, Ge. Artful Design: Technology in Search of the Sublime /
Written and Designed by Ge Wang. Stanford, CA: Stanford University
Press, 2018. <br> <br> <br><br></p>
<hr />
<p><br><br></p>
<h1 id="appendices">Appendices</h1>
<h2 id="appendix-a-video-documentation">Appendix A: Video
Documentation</h2>
<p><strong><em>I have hosted these Appendix Items on Vimeo for ease of
embedding them throughout the project. However, these Appendix Items can
also be found in the file directory of this project.</em></strong></p>
<h3 id="section-1-initial-pre-leapmotion-tests">Section 1: Initial
(Pre-LeapMotion) Tests</h3>
<p><a href="https://vimeo.com/712023668/8551957113"
title="Video 1.1">Video 1.1: Colour Tracking Ping Pong Ball with Trigger
Grid</a></p>
<p><a href="https://vimeo.com/711824231/62fb628ac8"
title="Video 1.2">Video 1.2: Computer Mouse with Trigger Grid</a></p>
<h3 id="section-2-pinch-sine-waves-demos">Section 2: Pinch Sine Waves
Demos</h3>
<p><a href="https://vimeo.com/711824231/62fb628ac8"
title="Video 2.1">Video 2.1: First LeapMotion Sound Test</a></p>
<p><a href="https://vimeo.com/716153349/07fa6fe0d9"
title="Video 2.2">Video 2.2: Pinch Sine Waves Prototype #01</a></p>
<p><a href="https://vimeo.com/732055948/3fef928cc2"
title="Video 2.3">Video 2.3: Dial Music (Pinch Sine Waves Prototype
#02)</a></p>
<h3 id="section-3-leapmotion-wekinator-experiments">Section 3:
LeapMotion + Wekinator Experiments</h3>
<p><a href="https://vimeo.com/715768491/0c359471b3"
title="Video 3.1">Video 3.1: Wekinator with Voice Sample</a></p>
<p><a href="https://vimeo.com/715955425/011dbe7187"
title="Video 3.2">Video 3.2: Wekinator with Wooden Recorder
Sample</a></p>
<h3 id="section-4-fm-velocity-synth">Section 4: FM Velocity Synth</h3>
<p><a href="https://vimeo.com/716558840/bbcc20eb5e"
title="Video 4.1">Video 4.1: Velocity-Volume Mapping Attempt #01</a></p>
<p><a href="https://vimeo.com/716560295/e2bacf9bfa"
title="Video 4.2">Video 4.2: Velocity-Volume Mapping Attempt #02</a></p>
<p><a href="https://vimeo.com/717038360/08b6e83c5a"
title="Video 4.3">Video 4.3: Velocity-Volume Mapping Attempt #03</a></p>
<p><a href="https://vimeo.com/717549821/97c20cc8bc"
title="Video 4.4">Video 4.4: FM Synth Prototype #01</a></p>
<p><a href="https://vimeo.com/718754603/98f4e093cf"
title="Video 4.5">Video 4.5: Fist Controlled Filter Demo</a></p>
<p><a href="https://vimeo.com/719103909/f0ad090a96"
title="Video 4.6">Video 4.6: FM Synth Prototype #02</a></p>
<p><a href="https://vimeo.com/719826180/035ab5f274"
title="Video 4.7">Video 4.7: FM Synth Prototype #03</a></p>
<h3 id="section-5-formant-filters">Section 5: Formant Filters</h3>
<p><a href="https://vimeo.com/721082004/bf7c14dc24"
title="Video 5.1">Video 5.1: Formant Filters Prototype #01</a></p>
<p><a href="https://vimeo.com/731322891/f2340fc086"
title="Video 5.2">Video 5.2: Formant Filters Prototype #02</a></p>
<p><a href="https://vimeo.com/741239191/c737ddd211"
title="Video 5.3">Video 5.3: Formant Filter Play Test - Andrew</a></p>
<p><a href="https://vimeo.com/741240744/4c644af02c"
title="Video 5.4">Video 5.4: Formant Filter Play Test - Lyla</a></p>
<h3 id="section-6-concatenative-synthesis">Section 6: Concatenative
Synthesis</h3>
<p><a href="https://vimeo.com/729246284/c0574ff4bc"
title="Video 6.1">Video 6.1: Concatenative Corpus Explorer Prototype
#01</a></p>
<p><a href="https://vimeo.com/731778144/db0cefb16e"
title="Video 6.2">Video 6.2: Concatenative Interaction with Panning
Demo</a></p>
<p><a href="https://vimeo.com/738253819/8dabc44794"
title="Video 6.3">Video 6.3: Concatenative Corpus Explorer Prototype
#02</a></p>
<p><a href="https://vimeo.com/741239049/a9e4be97fc"
title="Video 6.4">Video 6.4: Concatenative Play Test - Andrew</a></p>
<p><a href="https://vimeo.com/741240646/8e1af7fa71"
title="Video 6.5">Video 6.5: Concatenative Play Test - Lyla</a></p>
<h3 id="section-7-theremin">Section 7: Theremin</h3>
<p><a href="https://vimeo.com/731763449/08a0f66a80"
title="Video 7.1">Video 7.1: Theremin Prototype #01</a></p>
<p><a href="https://vimeo.com/731842798/079977e70b"
title="Video 7.2">Video 7.2: Theremin Changeable Orientation
Demo</a></p>
<p><a href="https://vimeo.com/738238191/3013552609"
title="Video 7.3">Video 7.3: Theremin Prototype #02</a></p>
<p><a href="https://vimeo.com/738257731/ceea028c41"
title="Video 7.4">Video 7.4: Theremin Vibrato Options Demo</a></p>
<h3 id="section-8-sampler">Section 8: Sampler</h3>
<p><a href="https://vimeo.com/733388258/8ba613c884"
title="Video 8.1">Video 8.1: Sampler Demo</a></p>
<h3 id="section-9-scrubbing-record-scratcher">Section 9: Scrubbing
(Record Scratcher)</h3>
<p><a href="https://vimeo.com/732199253/808d4b329c"
title="Video 9.1">Video 9.1: Audio Playback Control Attempt #01</a></p>
<p><a href="https://vimeo.com/732201910/109f9a3602"
title="Video 9.2">Video 9.2: Record Scratching Simulator</a></p>
<p><a href="https://vimeo.com/738292573/496962b10c"
title="Video 9.3">Video 9.3: Record Scratcher with Visual Feedback
Demo</a></p>
<h3 id="section-10-scrubbing-explorer">Section 10: Scrubbing
(Explorer)</h3>
<p><a href="https://vimeo.com/735959899/fb4109f33e"
title="Video 10.1">Video 10.1: Scrubber Explorer Prototype #01</a></p>
<p><a href="https://vimeo.com/738243186/a9243c39a8"
title="Video 10.2">Video 10.2: Scrubber Explorer Prototype #02</a></p>
<p><a href="https://vimeo.com/741239369/da15dd0b82"
title="Video 10.3">Video 10.3: Scrubber Explorer Play Test -
Andrew</a></p>
<p><a href="https://vimeo.com/741240938/0f6ec0dc15"
title="Video 10.4">Video 10.4: Scrubber Explorer Play Test -
Lyla</a></p>
<h3 id="section-11-magic-spells">Section 11: Magic Spells</h3>
<p><a href="https://vimeo.com/735441404/25a2d18748"
title="Video 11.1">Video 11.1: Magic Spells Prototype #01</a></p>
<p><a href="https://vimeo.com/735959022/8171e04534"
title="Video 11.2">Video 11.2: Magic Spells Prototype #02</a></p>
<p><a href="https://vimeo.com/738304157/e439f2bdd8"
title="Video 11.3">Video 11.3: Magic Spells Prototype #03</a></p>
<p><a href="https://vimeo.com/741239231/16039d8ebd"
title="Video 11.4">Video 11.4: Magic Spells Play Test - Andrew</a></p>
<p><a href="https://vimeo.com/741240846/47ce7435a2"
title="Video 11.5">Video 11.5: Magic Spells Play Test - Lyla</a></p>
<h3 id="section-12-piano-clouds">Section 12: Piano Clouds</h3>
<p><a href="link" title="Video 12.1">Video 12.1: Piano Clouds
Demo</a></p>
<p><a href="https://vimeo.com/741420844/1356e22d13"
title="Video 12.2">Video 12.2: Piano Clouds Different Chord Changing
Techniques Demo</a></p>
<p><a href="https://vimeo.com/741239295/0947db9564"
title="Video 12.3">Video 12.3: Piano Clouds Play Test - Andrew</a></p>
<p><a href="https://vimeo.com/741240876/905b1cbc73"
title="Video 12.4">Video 12.4: Piano Clouds Play Test - Lyla</a></p>
<p><br><br></p>
<h2 id="appendix-b-audio-documentation">Appendix B: Audio
Documentation</h2>
<p><strong><em>I have hosted these Appendix Items on SoundCloud for ease
of embedding them throughout the project. However, these Appendix Items
can also be found in the file directory of this
project.</em></strong></p>
<h3 id="section-1-andrew-play-testing-interviews">Section 1: Andrew Play
Testing Interviews</h3>
<p><a href="https://on.soundcloud.com/BsMh">Audio 1.1: Andrew Play Test
Interview - Scrubber Explorer</a></p>
<p><a href="https://on.soundcloud.com/QP8V">Audio 1.2: Andrew Play Test
Interview - Piano Clouds</a></p>
<p><a href="https://on.soundcloud.com/GrZ4">Audio 1.3: Andrew Play Test
Interview - Formant Filters</a></p>
<p><a href="https://on.soundcloud.com/yN6t">Audio 1.4: Andrew Play Test
Interview - Concatenative</a></p>
<p><a href="https://on.soundcloud.com/7asP">Audio 1.5: Andrew Play Test
Interview - Magic Spells</a></p>
<h3 id="section-2-lyla-play-testing-interviews">Section 2: Lyla Play
Testing Interviews</h3>
<p><a href="https://on.soundcloud.com/AD2E">Audio 2.1: Lyla Play Test
Interview - Scrubber Explorer</a></p>
<p><a href="https://on.soundcloud.com/aGtS">Audio 2.2: Lyla Play Test
Interview - Piano Clouds</a></p>
<p><a href="https://on.soundcloud.com/QuyP">Audio 2.3: Lyla Play Test
Interview - Formant Filters</a></p>
<p><a href="https://on.soundcloud.com/TVQD">Audio 2.4: Lyla Play Test
Interview - Concatenative</a></p>
<p><a href="https://on.soundcloud.com/sXxJ">Audio 2.5: Lyla Play Test
Interview - Magic Spells</a></p>
<p><br><br></p>
<p><a name="AppendixC"></a></p>
<h2 id="appendix-c-max-patches">Appendix C: Max Patches</h2>
<p><strong><em>These Appendix Items can be found in the file directory
of this project.</em></strong></p>
<p><strong>Patch 0:</strong> LeapMotionUnity.maxpat</p>
<p><strong>Patch 1:</strong> jr_LeapMotion_DialMusic.maxpat</p>
<p><strong>Patch 2:</strong> jr_LeapMotion_FM_Prototype02.maxpat</p>
<p><strong>Patch 3:</strong> jr_LeapMotion_Wekinator_MIDI_FX.maxpat</p>
<p><strong>Patch 4:</strong>
jr_LeapMotion_Scrubbing_RecordScratcher.maxpat</p>
<p><strong>Patch 5:</strong> jr_Concatenative.maxpat</p>
<p><strong>Patch 6:</strong> jr_LeapMotion_Theremin.maxpat</p>
<p><strong>Patch 7:</strong> jr_LeapMotion_Scrubbing_Explorer.maxpat</p>
<p><strong>Patch 8:</strong> jr_LeapMotion_Sampler.maxpat</p>
<p><strong>Patch 8.1:</strong> sampler_voice.maxpat</p>
<p><strong>Patch 9:</strong> jr_LeapMotion_FormantFilters.maxpat</p>
<p><strong>Patch 9.1:</strong> formantFilter_voice.maxpat</p>
<p><em>(N.B. Patch 9 also requires check.json and envelopes.json to be
in the same folder)</em></p>
<p><strong>Patch 10:</strong> jr_LeapMotion_MagicSpells.maxpat</p>
<p><strong>Patch 11:</strong> jr_PianoClouds.maxpat</p>
<p><strong>Patch 11.1:</strong> pianoSampler_voice_fader.maxpat</p>
<p><br><br></p>
<h2 id="appendix-d-other-software">Appendix D: Other Software</h2>
<p><a name="AppendixD"></a></p>
<p><strong><em>These Appendix Items can be found in the file directory
of this project.</em></strong></p>
<p><strong>Item 1 -</strong> ‘jr_LMOU_readme.txt’</p>
<ul>
<li><em>This is a readme documentation file to accompany the unity
application that I built to send data from the LeapMotion to OSC ports.
It details how the data can be read and approximate data
ranges.</em></li>
</ul>
<p><strong>Item 2 -</strong> ‘LeapMotion to OSC Application’</p>
<ul>
<li><em>This folder contains the ‘LeapMotionOSC.exe’ windows application
of the Unity Application that I use to send data from the LeapMotion to
OSC. I currently only have this built for Windows as the priority for
the project was getting the interactions working on my machine rather
than having them accessible on multiple operating systems for other
users.</em></li>
</ul>
<p><strong>Item 3 -</strong> ‘UnityOSC-master’</p>
<ul>
<li><em>This folder is the Unity project for the application that I made
to send LeapMotion data to OSC.</em></li>
</ul>
<p><strong>Item 4 -</strong> ‘LeapMotion-PD-Game_Unity’</p>
<ul>
<li><em>This folder is the Unity project that I started to build with
the intention of using pure data to integrate some of the interactions
into a standalone Unity application. It is currently not building
properly but I have included it for reference.</em></li>
</ul>
<p><strong>Item 5 -</strong> ‘pure data patches’</p>
<ul>
<li><em>These are some pure data patches that I made as ‘translations’
of some of my max MSP interactions so that I could use them in a Unity
application. The pure data patches were working but the issues I was
having with Unity made me decide to postpone this aspect of the project
until a later date. I have included them here for reference.</em></li>
</ul>
<p><strong>Item 5.1 -</strong> ‘FM_Synth.pd’</p>
<ul>
<li><em>This is a remake of my FM Synth interaction - approximately the
same as patch 2 in Appendix C.</em></li>
</ul>
<p><strong>Item 5.2 -</strong> ‘onebang.pd’</p>
<ul>
<li><em>This is a simple extraction I made in pd to emulate the</em>
<strong>onebang</strong> <em>object in max MSP.</em></li>
</ul>
<p><strong>Item 5.3 -</strong> ‘onebangWithoutPreset.pd’</p>
<ul>
<li><em>This is a simple extraction I made in pd to emulate the</em>
<strong>onebang</strong> <em>object in max MSP (that on awake requires
to be reset before passing any bang).</em></li>
</ul>
<p><strong>Item 5.4 -</strong> ‘scale.pd’</p>
<ul>
<li><em>This is a simple extraction I made in pd to emulate the</em>
<strong>scale</strong> <em>object in max MSP.</em></li>
</ul>
<p><strong>Item 5.5 -</strong> ‘scale~.pd’</p>
<ul>
<li><em>This is a simple extraction I made in pd to emulate the</em>
<strong>scale~</strong> <em>object in max MSP.</em></li>
</ul>
<p><strong>Item 5.6 -</strong> ‘Scrubbing.pd’ <em>This is a remake of my
Record Scratching interaction - approximately the same as patch 4 in
Appendix C.</em></p>
<p><strong>Item 5.7 -</strong> ‘spigot~.pd’</p>
<ul>
<li><em>This is a simple extraction I made in pd to allow use of the
spigot function with a signal.</em></li>
</ul>
<p><strong>Item 5.8 -</strong> ‘theremin.pd’</p>
<ul>
<li><em>This is a remake of my Theremin interaction - approximately the
same as patch 6 in Appendix C.</em></li>
</ul>
<p><strong>Item 6 -</strong> ‘Wekinator_Project’</p>
<ul>
<li><em>This is a folder which contains the
‘FiddleSticks_Wekinator.wekproj’ file which was used for Experiment 2.1
in Chapter 2 in conjunction with patch 3 in Appendix C.</em></li>
</ul>
<p><br><br></p>
<h2 id="appendix-e-blog-posts">Appendix E: Blog Posts</h2>
<p><strong><em>This Appendix contains selected blog posts from various
points throughout the project.</em></strong></p>
<p><a name="AppendixE1"></a></p>
<h3 id="item-1-sound-designed-futures-conference-30052022"><strong>Item
1:</strong> Sound Design(ed) Futures Conference (30/05/2022)</h3>
<p>I attended the Sound Design(ed) Futures Conference on the 27/05/2022
which was held online, hosted by the Université Gustave Eiffel and
organised by Eleni-Ira Panourgia and Andrea Giomi. Within this
conference I was particularly interested in the talks given by Sandra
Pauletto on her project focusing on sound design for energy, and Atau
Tanaka on his research into using AI to train physical gesture sound
interactions. After their talks, I asked the speakers how they found the
design of their gestures in terms of complexity affected the experience
of fun in the users. Whilst acknowledging that ‘fun’ is a subjective
term, Tanaka and Pauletto both provided some interesting insight into
this. Tanaka noted that fun seemed to be tied both to a level of
intuitive design, and a level of playfulness and ludic design. Ludic
here feels like a very interesting word to explore more - defined by the
oxford dictionary as “showing spontaneous and undirected playfulness,”
which feels like an interesting phrase to keep in mind whilst designing
interactions. Pauletto expanded further on this challenge of designing
playful interactions. She discussed that the research she is conducting
involves designing for a wide range of users (as it focuses on household
items sound design) which might include families and young children as
well as adults. Pauletto also spoke of how when designing to encourage
certain behaviour, they found that positive reinforcement was more
effective than negative reinforcement, or at least was certainly more
enjoyable and more likely to be adopted by a wider range of users.
Therefore, some of their research into how to design the sound of
household appliances to encourage better use of energy involves this
kind of design that attempts to make these items fun and enjoyable to
use.</p>
<p>Pauletto mentioned specifically that the sensation of a
<em>personalised experience</em> was connected with an enjoyable
experience. A wide range of users are always going to have particular
tastes and preferences that do not align with each other - and so the
more that a designer accommodates for this and allows a user to bring in
their own preferences to an experience, the more likely they are to
enjoy it. The example they gave was the singing shower designed by PhD
candidate Yann Seznec within the context of the wider research project.
The shower was activated when it detected sounds that had a sustained
pitch that it recognised as music (the user singing). A demo of this can
be seen here:</p>
<p><a
href="https://www.youtube.com/watch?v=Rl8BDxCqZwk&amp;ab_channel=YannSeznec"
title="The Singing Shower Prototype - Yann Seznec, 2022">The Singing
Shower Prototype (Yann Seznec, 2022)</a></p>
<p>This meant that even though there was a single design implemented for
all users, each user could sing their own preference of song, style,
volume etc. leading to a personalised user experience. This was very
inspiring to me, and encouraged me to begin implementing these less
prescriptive physical gesture mappings. With the velocity trigger system
that I outlined in the above section, there is a similar personalised
experience in that the user is able to move their hand in any direction
with any kind of additional flair to achieve the same sound output. This
hopefully will result in a more fun experience for the user where they
can make the physical interaction more catered towards their specific
preferences for what physical hand gestures they want to make the sound
with. <br><br></p>
<p><a name="AppendixE2"></a></p>
<h3
id="item-2-play-testing-questionnaire-setup-and-evaluation-19082022"><strong>Item
2:</strong> Play Testing Questionnaire, Setup, and Evaluation
(19/08/2022)</h3>
<p><strong>Questions for Participants - asked verbally in conversation
after each interaction</strong></p>
<ol type="1">
<li><p>What are a few words you would use to describe this
experience?</p></li>
<li><p>What do you enjoy most about this interaction, if
anything?</p></li>
<li><p>What do you find the most frustrating/annoying about this
interaction, if anything?</p></li>
<li><p>How would you categorise/conceptualise this experience? For
example: Playing a musical instrument / A creative tool for making
sounds / Just playing / Playing a game / An educational experience
etc.</p></li>
<li><p>Any other thoughts/associations/feelings/ideas that come to you
from this experience?</p></li>
</ol>
<p>I tried to avoid making these questions too leading. I focused on the
broad ideas of things they enjoyed and didn’t enjoy to try to coax out
ideas that might be relevant to my idea of joy without putting a word
like joy directly into their minds as vocabulary.</p>
<p><strong>Limitations of this Study</strong></p>
<p>It is worth noting the severe limitations of this play testing study.
As I note in my project reflection, my time and resource limitations
during the project meant that I didn’t manage to conduct as rigorous a
play test study as I would have liked. However, because of the insight
that other users can provide on my own evaluations I felt that it was
still worth conducting this very limited study.</p>
<p>It is also worth noting that the two participants represent a very
small proportion of potential users for these interactions and both come
with their own potential biases. In particular, the results gathered
from this study may be influenced by the fact that both participants are
highly trained musicians (guitar and violin), and Andrew is a sound
designer who is familiar with max MSP. These factors mean that as
participants Andrew and Lyla have a very specific, potentially more
informed than is usual in the general public, relationship with sound,
music and making sounds. These aspects also make them very interesting
participants and I found their feedback incredibly insightful, but the
bias is important to acknowledge.</p>
<p><strong>Study Method</strong></p>
<p>The study involved only two participants: Andrew and Lyla. I invited
each of them into a room where the LeapMotion and laptop with the
interaction was set up and then went through the <strong>following
steps:</strong></p>
<ol type="1">
<li><p>Explain briefly the ‘controls’ of the interaction and the set up
of their interaction being filmed and interview recorded</p></li>
<li><p>Stand back and allow them to play with the interactions</p></li>
<li><p>They were told to let me know when they were ready to discuss the
interaction at any point, and if they didn’t stop before 10 minutes, I
would stop them to initiate the interview.</p></li>
<li><p>I asked them the questions above and recorded the verbal
interviews. The audio files of these interviews were later referred to
for quotes</p></li>
<li><p>I rotated between the participants so that they had breaks
between each interaction, and asked the other participant to wait in
another room whilst they were not taking part so that they were less
likely to be influenced by the other participant’s thoughts
<br><br></p></li>
</ol>
<p><a name="AppendixE3"></a></p>
<h3 id="item-3-technical-notes-for-experiment-1.1"><strong>Item
3:</strong> Technical Notes for Experiment 1.1</h3>
<p><strong>Prototype 01 aka Pinch Sine Waves</strong></p>
<p>This interaction uses simple 1:1 mappings:</p>
<ul>
<li>pinch amount controls oscillator volume</li>
<li>hand rotation controls oscillator frequency</li>
<li>each hand controls a distinct oscillator</li>
</ul>
<p><strong>Prototype 02 aka Dial Music</strong></p>
<p>This interaction uses more musically focused mappings:</p>
<ul>
<li>introducing discrete pitches in the frequency control so that a
musical scale (C Major) could be explored</li>
<li>connecting the y-axis to frequency as well so that y-position would
dictate what octave of the scale is played</li>
<li>added a delay effect that was controlled by the distance between the
two hands to add more possibility for varied expression</li>
<li>pinch still controls volume <br><br></li>
</ul>
<h4
id="item-3.1-technical-note---continuous-vs.-discrete-data"><strong>Item
3.1:</strong> Technical Note - Continuous vs. Discrete Data</h4>
<p>This experiment made me consider the strengths and limitations of
continuous data values versus discrete data values. The data coming from
the LeapMotion is almost all continuous (the exception being a bool for
whether the hand is present), and so in the first prototype I kept the
parameters that the data was controlling continuous as well to try to
make the mapping as simple (and therefore as intuitive) as possible.</p>
<p>The strengths of this approach were that it allowed me to make the
system very responsive. Because the LeapMotion data being sent through
OSC is so accurate, it needs to be smoothed before being used to control
audio in order to avoid clicks and noise that didn’t fit my aesthetic
aims. When keeping the output data as continuous, this smoothing is the
only factor connecting the users movement input to the audio output
(especially in 1:1 mapping as in this case). This means that the system
can be made extremely responsive, with even small movements producing
audible changes in the output. This also helps the user develop a
conceptual model of the interaction, as the fast response speeds up the
feedback loop of a user so that they can more quickly deduce what in
their input is causing what in the output.</p>
<p>In the second prototype, I went for a different approach with
pitch/frequency where I mapped the continuous input into a set of
discrete points with smoothing set for when moving between these
distinct points. The discrete points correspond to discrete musical
notes in a particular musical scale. For this prototype I decided to use
the scale C Major. This approach still maintains a certain sense of
continuous-ness due to the smoothing in between the notes. However
overall some of the sensitivity of the continuous to continuous approach
is sacrificed here for an increase in reliability. By reliability here I
refer to the ability to reliably recall a specific frequency. This is
made more feasible with the continuous to discrete approach, as larger
physical actions are required to change the frequency and it is easier
to hear the distinct frequencies and identify when they have been
successfully reached or not. <br><br></p>
<p><a name="AppendixE4"></a></p>
<h3 id="item-4-technical-notes-for-experiment-1.2"><strong>Item
4:</strong> Technical Notes for Experiment 1.2</h3>
<p><strong>Sampler</strong></p>
<p>This interaction uses a velocity based threshold trigger system. When
a hand moves above a certain velocity threshold, an sample is triggered.
To add variety and ‘playability’ through more varied sounds, I set the
interaction up such that each direction of velocity triggered it’s own
dedicated sample - giving 12 total samples that could be triggered.
(This was achieved by giving each velocity component a negative
threshold and a positive threshold)</p>
<p>The quantise mode is a mode in which triggers are delayed and then
sent out by a metronome on the next beat (determined by the metronomes
interval). This means that the system is less responsive, but sonically
sounds more musical and ‘in-time’. <br><br></p>
<p><a name="AppendixE5"></a></p>
<h3 id="item-5-technical-notes-for-experiment-1.3"><strong>Item
5:</strong> Technical Notes for Experiment 1.3</h3>
<p><strong>Piano Clouds</strong></p>
<p>The mechanics of this interaction are:</p>
<ul>
<li>moving the position of the right hand in the x-y plane triggers
random piano samples (this is trigger grid system - the x and y
positions are scaled to a range of 10 integers and each time an integer
value changes, a trigger is sent)</li>
<li>opening and closing the left fist fades between four possible chords
(all related: I, IV, V, vi of B Major) (this is achieved by having the
output of all possible chords constantly playing, and then using the
chord index from the hand data to control a fader system that sets which
chord is audible, and fades between them as they change for smooth
transitions)</li>
</ul>
<p>For an interesting comparison of an alternative chord change system
that I tried but felt didn’t offer the same expressive capabilities, see
here:</p>
<p><a href="https://vimeo.com/741420844/1356e22d13"
title="Video 12.2">Appendix A - Video 12.2: Piano Clouds Different Chord
Changing Techniques Demo</a></p>
<p>I thought as well that this would be a simple interaction to use to
play music casually with another ‘live’ musical instrument - with the
simple triad chords being easily used as an accompaniment.</p>
<p>An interesting technical aspect of this patch was designing a voice
stealing system that avoided clicks. The audio files are each 8 seconds
long, meaning that voices are stolen very often. In order to stop this
stealing causing clicks, I added a 50ms fade at the beginning of each
sample trigger in the poly patch, and also made a system that checks if
the triggered voice is being stolen (by checking whether the voice is
busy when the trigger is sent), if it is then a 100ms fade out is
triggered before triggering a sample as normal. In other interactions
the latency caused by this might make the interaction feel less
responsive, but due to the more random feel of the triggering system in
this interaction I was able to implement it without issue. <br><br></p>
<p><a name="AppendixE6"></a></p>
<h3 id="item-6-technical-notes-for-experiment-2.1"><strong>Item
6:</strong> Technical Notes for Experiment 2.1</h3>
<p><strong>Wekinator MIDI Controller</strong></p>
<p>I chose the Valhalla Frequency Echo plugin for this interaction as it
has multiple parameters [delay length (in ms), frequency shift amount
(in Hz) and feedback amount (%)] which each have the ability to affect
the sound output in relatively extreme ways, relatively independent of
each other. I also thought these specific controls would be interesting
as they have similar affects on the pitch of the output sound, but
through very different techniques - I hoped this would further confuse
the users conceptual model of what they were actually controlling in
this interaction.</p>
<p>I set up the X Y and Z position values for the left hand to be sent
through Wekinator. I then used this data to train 4 different spatial
positions for the left hand and connect them to parameter settings for
the 3 chosen plugin parameters that would result in 4 very different
states for the plugin. Wekinator allowed me to use machine learning in
this way to train complex interpolation of the left hands positional
data to control the 3 chosen parameters of the Frequency Echo plugin in
a non-linear and complex way.</p>
<p>As an audio source I chose two different audio files for two
different tests (which can be heard in each respective video demo of
this interaction). I looped the audio so that there was constantly audio
to manipulate with the plugin. <br><br></p>
<p><a name="AppendixE7"></a></p>
<h3 id="item-7-techinical-notes-for-experiment-2.2"><strong>Item
7:</strong> Techinical Notes for Experiment 2.2</h3>
<p><strong>Formant Filters</strong></p>
<p><strong>Prototype 01</strong></p>
<p>This prototype was more concerned with simple limited control actions
being used to manipulate a sonically complex output:</p>
<ul>
<li>opening and closing the fists changes the vowel shape of the sound
(continuous interpolation between presets of the formant frequencies for
3 distinct formants)</li>
<li>y-axis position controls the frequency</li>
<li>the sound volume is constantly ON when any hand is present, and OFF
when both hands are absent</li>
</ul>
<p><strong>Prototype 02</strong></p>
<p>This prototype explored a combination of varying styles of control to
create a complex interface:</p>
<ul>
<li>moving either hand beyond a set velocity threshold triggers a 400ms
segment of sound to be played (polyphonically)</li>
<li>moving the x-position of the left hand interpolates between
different presets of shapes for a volume envelope and a frequency
envelope</li>
<li>vowel shape is still controlled in the same way, but preset vowel
shapes are now distinguished as 10 discrete points in the scale that are
smoothed between so that it is easier to stay on a particular vowel
<br><br></li>
</ul>
<p><a name="AppendixE8"></a></p>
<h3 id="item-8-technical-notes-for-experiment-2.3"><strong>Item
8:</strong> Technical Notes for Experiment 2.3</h3>
<p><strong>Concatenative Corpus Explorer</strong></p>
<ul>
<li>the x-y position of the left hand moves around the 2D map of audio
slices from the corpus, determining which plays on a loop</li>
<li>opening and closing the right hand controls volume: closing in a
fist silences the interaction</li>
<li>opening and closing the left hand changes the length of a stereo
delay line (this pitch shift when fluttering the fingers felt
aesthetically satisfying)</li>
<li>rotating the right hand fades in a low-pass filter</li>
</ul>
<p>I included three corpuses in the patch to choose from: a small
‘glitchy’ library that had quite smooth synthy sounds, a ‘friction’
library that was more rough and had some airy movement sounds, and a
‘mechanical’ library that had more clicky buttons or metallic bell like
sounds. All of these recordings were ones I had recorded myself for
previous projects.</p>
<p>I was quite happy with the filter implementation here - instead of
mapping the hand rotation solely to the cut-off frequency of the filter,
I mapped it to both the cut-off frequency and an overall dry/wet mix, so
that the cut-off could be controlled in a specific range, whilst still
having a completely dry signal when the hand is in it’s ‘un-rotated’
position. <br><br></p>
<p><a name="AppendixE9"></a></p>
<h3 id="item-9-technical-notes-for-experiment-3.1"><strong>Item
9:</strong> Technical Notes for Experiment 3.1</h3>
<p><strong>FM Synth</strong></p>
<p>I had a tough time figuring out the velocity control of volume.
Failed attempts can be seen/heard here:</p>
<p><a href="https://vimeo.com/716558840/bbcc20eb5e"
title="Video 4.1">Appendix A - Video 4.1: Velocity-Volume Mapping
Attempt #01</a></p>
<p><a href="https://vimeo.com/716560295/e2bacf9bfa"
title="Video 4.2">Appendix A - Video 4.2: Velocity-Volume Mapping
Attempt #02</a></p>
<p><a href="https://vimeo.com/717038360/08b6e83c5a"
title="Video 4.3">Appendix A - Video 4.3: Velocity-Volume Mapping
Attempt #03</a></p>
<p>Eventually I managed to find a combination of very specific smoothing
systems (using both <strong>line~</strong> objects and low-pass filters
to smooth the data in signal form), as well as a system that started
timing whenever a hand went out of view, and faded the volume and all
other parameters out once the hand had been absent for approximately
300ms. This 300ms delay prevented the system from cutting the volume
every time the camera lost sight of the hand momentarily, which happens
more often when the hands are moving fast.</p>
<p>I made each hand control a distinct synth voice, as this seemed to
follow a physical logic that they are separate beings. I did however
give them the same basic controls so that there was a coherent sense of
what ‘a hand’ sounded like. To give a bit more characteristic separation
to each hand I gave them different parameter ranges - again this felt
physically logical to me as each of our hands is very similar but feels
clearly distinct in character. I hoped that following this form of
physical logic the sound would feel more of a logical extension of the
body rather than an arbitrary sound being controlled by it.</p>
<p>I also mapped a low-pass filter on each synth to how closed the hand
was. This felt appropriate as I wanted some kind of sonic way to
distinguish the hand being open or closed, as these feel like such
different actions physically. I thought that by mapping a low-pass
filter to the hand closing, it would further create the sensation that
the sounds are coming <em>from</em> the hands, and therefore when they
are closed the sound comes out ‘muffled’ in this way.</p>
<p>To add a greater sense of sonic interest I added in a system of LFOs
that only affect the sound when both hands are present. <br><br></p>
<p><a name="AppendixE10"></a></p>
<h3 id="item-10-technical-notes-for-experiment-3.2"><strong>Item
10:</strong> Technical Notes for Experiment 3.2</h3>
<p><strong>Scrubber Explorer</strong></p>
<p>I added in a randomising mode that I hoped would provide a more
playful experience where the user wouldn’t need to interact with the max
interface as much with the mouse. In this mode, each time a hand closed
fully, the position in the audio buffer that it is controlling will
randomly change.</p>
<p>I enjoyed manipulating playback rate in this interaction as playback
rate also has the added benefit of affecting multiple qualities of the
sound through a single parameter, i.e volume, pitch, and timbre.</p>
<p>Each hand’s velocity is mapped slightly differently to playback rate
so that even when they are both using the same point in the same buffer,
they have a slightly different character and feel.</p>
<p>I also added a stereo delay line to give the sound more of a sense of
movement and width. I also had the open and closing of the fists control
the length of this delay line as I find the pitch shifting this results
in very descriptive of the action of fluttering ones fingers
<br><br></p>
<p><a name="AppendixE11"></a></p>
<h3 id="item-11-technical-notes-for-experiment-3.3"><strong>Item
11:</strong> Technical Notes for Experiment 3.3</h3>
<p><strong>Magic Spells</strong></p>
<p>During the charging phases of the spells, I used synth systems such
as those in experiment 3.1 and 3.2 to create sounds that would respond
in real-time to the hand moving around the interaction space, whilst
also controlling some of the parameters with a time based envelope that
would make the sounds change and become more intense over time even if
the hand wasn’t moved, to reflect the growing power of the charging
spell. I also added in features such as LFOs and filtered noise that
only begin to affect parameters once a spell is fully charged, so that
if a user continues to hold a spell after it is fully charged, this kind
of turbulence in the sound parameters reflects the unstable energy of
the spell that is waiting to be released.</p>
<p>Then for the release of the spell I designed transient samples
comprised of 3 layers. Each layer aimed to add more weight to the sound,
and either 1, 2 or all of the layers would be triggered depending on how
long the spell had been charged. This aimed to support the sensation
that a spell that had been charged for longer was more similar but more
powerful to the same spell charged for less time. Each layer had slight
variations so that multiple spells cast in succession would still sound
varied. <br><br></p>
<p><a name="AppendixE12"></a></p>
<h3 id="item-12-the-failures-of-this-project"><strong>Item 12:</strong>
The Failures of this Project</h3>
<p><strong>The Failure to Investigate Different Interfaces</strong></p>
<ul>
<li>At a few stages in this project I have encountered failures that
have shifted my path and informed my process. The first of these was the
failure to expand the scale of the interactions. Originally, I had
wanted to explore physical sound interactions more broadly by using and
exploring multiple kinds of physical sound interface and investigating
the joyful possibilities of each. However, I had a bad experience
attempting to integrate a VIVE VR setup which included tracker objects
that could be accurately tracked within a space. This was mainly due to
limitations with personal computer processing capability, and also not
having access to a space that I could easily have this system set up in
for long periods of time whilst still being able to debug it and design
for it whilst it is set up (the system required a large empty space
where cameras could be set up). However, this failure also ended up
helping me to hone and focus the scope of the project. I realised as I
was struggling with the physical and technical difficulties of this new
set up that I was also struggling to conceptualise in my head how I
would transfer my work into a new interface. This made me realise that
for this project I was much more interested in the technical specifics
of designing sound interactions for <em>an interface</em>, with the
focus being on how I negotiate the data and input/output possibilities.
Therefore I decided to keep my focus on a single interface for this
project, so that I could prioritise exploring the many ways to design
for a single set of inputs, rather than getting overwhelmed or
distracted by setting up many different interfaces only to investigate
each less thoroughly than I would otherwise be able to.</li>
</ul>
<p><strong>The Failure to Package the Interactions Into a Single
Application</strong></p>
<ul>
<li>Another failure was to create a streamlined package in which the
sound interactions could be experienced through a single software
application. Once I had created a large number of interactions in max
MSP that I was happy with, I wanted to try to take them to the next
logical step in terms of being easily accessible and usable by members
of the general public. To me this involved creating a single Unity
Application that would allow you to select from a number of interactions
that I had designed and use them with the LeapMotion without having to
open any other software. I approached this by adding the libpd wrapper
plugin made by Niall Moody to my Unity project that already had the
LeapMotion plugin working. I remade a few of my max MSP patches in pure
data and imported them into the Unity project. This had initial success
and even allowed me to play with some visual possibilities that Unity
offered (see a demo of one such experiment here: <a
href="https://vimeo.com/738292573/496962b10c" title="Video 9.3">Appendix
A - Video 9.3: Pd + Unity Record Scrubber</a>. However, I encountered
issues with the Unity project where the builds would not track the
LeapMotion hands, and the editor would crash extremely regularly when
updating code. I began to debug this, however after a few days of
continued failure to find and fix the problem, I decided to leave this
part of the project for future development as it was costing a huge
amount of time and when I analysed why I was doing it, it was more
focused on wrapping the project up in a software that made it feel
neater and easier to engage with than actually continuing my
investigation of joyful interactions. Therefore, whilst I still want to
develop this aspect further, it was beyond the scope of this project and
was therefore discarded.</li>
</ul>
<p><strong>The Failure to Run User Studies</strong></p>
<ul>
<li>The biggest failure, in my opinion, of this project was to not
integrate a more signifcant form of study within the project where I
gather responses to the various interactions from a group of people who
are not me. I was aware at various points that this was a possible
route, but decided early on that due to the contentious nature of
defining joy it would be most useful to first focus on my own experience
and tastes. I still stand by this decision, as I think as a designer it
is important for me to establish my own tastes and experiential
preferences in order to inform my own artistic style. However I do feel
that having established my personal preferences, the experiments would
have really benefitted from feedback from a wider range of users who
could shed light on how these attempts at creating joy might be
interpreted by others who might have less knowledge of the project and
its aims. This was especially apparent once I ran the limited study that
I was able to where I had <a href="#AppendixE2">two participants test
play 5 of my interactions</a>. Even this small study was really eye (and
ear) opening, and made me feel a lot of new excitement for the
project.</li>
</ul>
<p><a name="AppendixE13"></a></p>
<h3 id="item-13-the-future-of-this-project"><strong>Item 13:</strong>
The Future of This Project</h3>
<p><strong>Development For Software Users</strong></p>
<p>I would like to develop these interactions by building them into a
single software, most likely made in unity, that can be hosted for free
on sites such as itch.co where any interested user with a LeapMotion
will be able to download it and try out the interactions. I think this
would be beneficial to the documentation of the work I have done thus
far, as a built unity application will be more stable over time than the
rest of the patches that I have made so it will more concretely ‘freeze’
the interactions for future reference.</p>
<p><strong>Development for Personal Practice</strong></p>
<p>Having started to touch upon more aesthetic issues near the end of
this project, I would like to dedicate more work into taking what I have
learnt from these experiments and using them to make a piece or
installation that has a more distinct artistic aim for me creatively. I
can imagine this taking the form of both performances with the
LeapMotion, designing interactions that are meant to be performed by me,
and also installations where I design interactions around a specific
artistic theme or idea that are meant to be interacted with a general
audience within a space. I think this move from a more general
experimental model into a more creatively driven artistic practice will
be beneficial for informing my design process further. As Perry Cook
suggests when designing digital musical interfaces: “Make a
<em>piece</em>, not an instrument or controller” (pg.229) - suggesting
that a focus on the instrument can make you lose sight of what you
actually want it to do or how you want to use it, whereas designing an
interaction for a specific piece or performance will inevitably result
in an instrument through the process.</p>
<p><strong>Development for Different Interfaces</strong></p>
<p>I would like to take some of the principles on joyful interactions
that I have found from these experiments and try applying them to
different interfaces - and combinations of interfaces. The interface
definitely influences the ways that I interpret these design principles,
and so I think that further investigation into how these principles
exist/manifest (or don’t exist) within other interfaces would help to
strengthen my understanding of how these physical sound interactions can
be thoughtfully designed. <br><br></p>
<p><a name="AppendixE14"></a></p>
<h3 id="item-14-my-design-take-aways"><strong>Item 14:</strong> My
design take-aways</h3>
<ul>
<li><p><strong><em>Responsive systems are joyful</em></strong></p>
<ul>
<li>When a system responds quickly it feels more connected to me and I
feel joy for being able to influence it. <br><br></li>
</ul></li>
<li><p><strong><em>Direct mapping of energy in the input to energy in
the output is joyful</em></strong></p>
<ul>
<li>The connection of energy in my gestures through velocity to a
parameter such as volume that fundamentally requires greater energy at
higher values is very satisfying. It allows for appropriate scaling of
the interaction, where if I make a small energy gesture, the system will
respond appropriately. I find this joyful because the mimicking of
energy between the system and myself allows me to see more of myself
within the sound output, allowing me also to project my intended
emotions or character that I put into the input, in the output. This
makes the interaction feel very expressive to me, which to me is joyful.
<br><br></li>
</ul></li>
<li><p><strong><em>The ability to construct/sculpt phrases is
joyful</em></strong></p>
<ul>
<li>I returned on multiple occasions to the mapping of volume to how
open or closed the fist was. This felt like it was because it really
gave me the impression of control over sonic phrasing. For me this
expressive control over broad gestures was more joyful than minute
control over smaller details in the sound output. I think of this as the
difference between being able to construct sentences/phrases in speech
vs. being able to change the accent of speech. Both have influence over
the meanings and emotions of the final output, but to me being able to
construct phrases that could then become a series of phrases opened up
joyful expressive possibilities. <br><br></li>
</ul></li>
<li><p><strong><em>Aesthetic connection between input and output is
joyful</em></strong></p>
<ul>
<li>Here I refer to the connection between an input and output that
<em>feels</em> right. This could be aesthetically in terms of some
projected meaning such as my Magic Spell interactions, where the magic
sound output feels like it justifies the physical actions that mimic
casting a magic spell and vice versa, or it could be aesthetically in a
more abstract sense where the physical action and sound feel sympathetic
in character. For example the mapping of a closed hand to a low-pass
filter, where the action of closing the hand <em>feels</em> similar to
the way a low-pass filter sounds when applied to a sound. <br><br></li>
</ul></li>
</ul>
<p>There were many other insights into physical sound interactions that
I gained, as documented in the experimental evaluations in this write
up, but for me these points above stood out as pivotal ideas for me that
have influenced the way that I analyse and design these kinds of
interactions. Moreover, these are the ideas that helped me grasp the
ways that I experience joy within these interactions. Joy is undoubtedly
a subjective experience that will mean different things for different
people at different points of their lives, which is exactly why for me
as a designer it is so useful to take this research opportunity to break
it down a bit and analyse personally what joy means to me <em>now</em>
within these interactions. Having made these conclusions, I look forward
to taking these concepts into my future design work and seeing how my
understanding and experience of them changes over time. I think it was
always an over-ambitious goal to capture the essence of joy in a way
that could be easily identified and bottled for easy access, but this
project has been an excellent exercise in taking an emotional and
experiential end goal, exploring and experimenting the many ways in
which I might achieve it, and importantly evaluating why they do and
don’t work (for me and possibly for others). <br><br></p>
<p><a name="AppendixE15"></a></p>
<h3 id="item-15-a-note-on-my-role-within-this-project"><strong>Item
15:</strong> A Note on My Role Within This Project</h3>
<ul>
<li>My role within this project has been a contested one. I approached
it first thinking of myself as a sound designer, and then over the
course of the project began to think of myself more as an interaction
designer - taking into consideration much more than just sound but also
the interfaces and the people who were intended to use them. In
reflection of this project I think my role would probably be more
accurately described as software developer/engineer/designer. Whilst I
still consider myself a sound designer, this project really spent most
of it’s details on how I could leverage <em>software</em> and data
processing to achieve sound design possibilities, rather than getting
into deep exploration of the sound design possibilities themselves.
Similarly, whilst I did consider the user within all of the
interactions, I didn’t expand my project to include the human testing
that might be involved in rigorous interaction design. Ultimately the
user considered within this project was myself. This limits the project,
but for myself it has been greatly useful in identifying the aspects of
these interactions that are joyful to me <em>within</em> the design
process itself: the software and data mapping. So whilst I prefer the
multidisciplinary label of <em>interaction designer</em> who might be
engaged in tasks that range through sound design, software engineering,
electrical engineering, and other areas, I acknowledge that in this
project I have largely worked as a software engineer, thinking on how
the software components can be designed to enable certain interactions
that I find joyful. <br><br></li>
</ul>
<p><a name="AppendixE16"></a></p>
<h3
id="item-16-techinical-note-on-how-i-connected-the-leapmotion-to-max-msp"><strong>Item
16:</strong> Techinical Note on How I Connected the LeapMotion to Max
MSP</h3>
<p>When I first managed to get hold of the LeapMotion camera, I couldn’t
find any immediately obvious way to connect it to max MSP. I found some
references to old max MSP external objects that had been made to
interface the two, but these were 5-6 years old and I couldn’t get them
to work (various forum posts suggested others had had the same
issues).</p>
<p>UltraLeap, who make the LeapMotion, do offer free plugins for Unity
and Unreal however which allow you to connect the LeapMotion to these
game engines.</p>
<p>I therefore set about making my own interface application in Unity
using the LeapMotion plugin, and <a
href="https://thomasfredericks.github.io/UnityOSC/">Thomas Frederick’s
plugin</a> for connecting unity to OSC. The results of this can be seen
in <a href="#AppendixD"><strong>Appendix D, Item 2</strong></a>, with an
accompanying readme file in <a href="#AppendixD"><strong>Appendix D,
Item 1</strong></a>.</p>
<p>I was really proud of this development, creating child classes from
the classes shipped with the LeapMotion plugin so that I could easily
adapt the code to send data via OSC without having to seriously tinker
with their code too much directly (the only change I ended up having to
make in their code directly was changing some variables from ‘private’
to ‘protected’, so that they could be accessed in the child classes that
I made).</p>
<p>I also used this as an opportunity to exercise a bit of software
design logic, trying to make the application as intuitive to a new user
as possible - even if it still feels fairly clunky due to its basic
visual and UI design.</p>
<p>After I had established this system, I later discovered that I had
somehow missed the existence of the <a
href="https://uwyn.com/geco/">GECO application</a> which is a now free
application designed specifically to connect data from the LeapMotion to
MIDI and OSC with a user friendly interface and all.</p>
<p>This was disappointing to see that I could have saved myself some
work, however I did actually love the challenge of connecting the data
in such a manual hands-on way. I also think that ultimately this helped
my designs.</p>
<p>By going in and finding and sending all of the data values manually,
I became much more familiar with the nautre of all of the data coming
from the LeapMotion and it’s ranges and behaviour etc.</p>
<p>I think this is a beneficial approach because it helps bypass some of
the bias caused by the apparent affordances suggested by the data being
already packaged for you in a specific interface. This was discussed a
bit by Yann Seznec during a feedback session for a work in progress of
this project during the Future Flavours of Sound Festival 2022.<a
href="#fn43" class="footnote-ref" id="fnref43"
role="doc-noteref"><sup>43</sup></a> Yann mentioned how it is possible
with these kind of interfaces to not notice how much they are suggesting
ways of use to you through the data that they make available. For
example, when they give you the velocity of the hand as a value, you
feel like you should use it. Yann brought this up to emphasise the
importance of stepping back and really thinking carefully about
<em>why</em> I am choosing certain input values as controls, and how
they are serving the interaction aesthetically and practically (if at
all!).</p>
<p>Therefore, whilst this technical excursion within the project was
slightly superfluous I think it served a useful purpose in informing my
design approach, both as an exercise in designing an interface in Unity
and as a way of thinking of data in a more RAW basic way to allow for
more thoughtful and careful design. <br><br></p>
<p><a name="AppendixE17"></a></p>
<h3 id="item-17-a-note-on-joy-through-surprise"><strong>Item
17:</strong> A Note on Joy Through Surprise</h3>
<p>The joy through surprise noted in <strong>Experiment 2.1</strong>
made me consider how surprise is joyful when the output <em>exceeds</em>
our expectations in some way. From my experience, the surprise of having
<strong>less</strong> impact on the sonic output than expected with an
input gesture is more disappointing and frustrating, whereas the
surprise of having <strong>more</strong> impact on the sonic output than
expected is much more <strong>funny</strong> and
<strong>joyful</strong>.</p>
<p>This feels like a fairly obvious observation, but still one I find
difficult to justify concretely. There can also be humour and joy
sometimes in the <strong>humility</strong> involved in an interaction
when you try to do a huge elaborate action and <strong>fail</strong> in
some way. This could be seen as an example of <strong>joy</strong>
through the surprise of having <strong>less impact</strong> than
expected.</p>
<p>However, in general from my experience with the experiments within
this project I have found that <strong>for a surprise to be joyful it
must be surprising due to exceeding expectations</strong>.</p>
<p><br><br></p>
<h2 id="appendix-f-quotes">Appendix F: Quotes</h2>
<p><a name="AppendixF1"></a></p>
<h3 id="section-1-playtesting-quotes"><strong>Section 1:</strong>
Playtesting Quotes</h3>
<p><strong><em>This section includes some quotes taken from interviews
with Andrew and Lyla after they had tested each respective interaction -
these quotes are extensive but still selective. For the full verbatim
interviews, see the audio recordings in Appendix B.</em></strong></p>
<h4 id="andrew---scrubbing-explorer">Andrew - Scrubbing Explorer</h4>
<ul>
<li><p>“…creative, I feel like you’re allowed to be really creative
while you’re playing with them because there are so many
options.”</p></li>
<li><p>“interesting, it’s a really interesting way of controlling
audio.”</p></li>
<li><p>“I really liked being able to find a specific part of the audio
file that you could then control… then that being randomised I feel like
keeps things really interesting and really fresh each time you start
moving around because its like really playful.”</p></li>
<li><p>“Not being able to cross my hands over well… I found that kind of
annoying”</p></li>
<li><p>“It definitely reminds me of like playing with records and like
trying to figure how to do live scratching with records which is always
super fun”</p></li>
<li><p>“The singing bowl one on its own I feel like is not as fun to
mess with because it’s such a constant sound… but the plastic bag and
the paper tearing because they’re so like textural… it makes you feel
like you’re really controlling every little particle that happens within
the sound which is really fun”</p></li>
<li><p>“I definitely feel like it’s for me definitely more of like a
creative tool, like I can definitely see myself trying to use this in
combination with like other musical tools to have like a sense of
randomness in a performance or some kind of aleatoric motion… I feel
like that would be really fun and really captivating for people to watch
as well, and hear”</p></li>
</ul>
<h4 id="andrew---piano-clouds">Andrew - Piano Clouds</h4>
<ul>
<li><p>“I’d say that was very relaxing… it’s kind of meditative in a
way”</p></li>
<li><p>“I really don’t think this one’s as much of a creative
tool”</p></li>
<li><p>“I don’t think it’s as playful as the other one… [the Scrubber
Explorer interaction] even though it’s very fun to play with, I don’t
think of it as playful. It’s more of like an experience, of being able
to waft your hands through the notes of the piano randomly”</p></li>
<li><p>“…because it’s randomised it definitely makes it feel not like an
instrument because you don’t really have as precise control over it
either, so it definitely feels more like an experience than playful,
creative, or like an instrument I think”</p></li>
<li><p>“…isn’t really like a game but it is playful”</p></li>
<li><p>“I really liked trying to make musical phrases with it which was
harder than I thought it would be because [I would] try to barely move
and just move one finger and then sometimes it would only play one note
but then sometimes it would play like four notes. So like playing with
that to try to like see how I can control the flow of the notes was
really interesting”</p></li>
<li><p>“I also liked a lot that it was triggering the bass notes and the
high notes at the same time so you didn’t really have control over that
but it made it feel more like a musical piece that you’re like
controlling rather than actively composing I guess”</p></li>
<li><p>“I think [not having complete control over how many notes were
played] was very fun”</p></li>
<li><p>“the thing I found that was kind of frustrating was when you
changed the left hand to change the chord… when you triggered any notes
while it was changing it would be kind of weird and kind of break the
relaxing experience of it a bit”</p></li>
<li><p>“…if you take away your fist [that controls the chord type] it
doesn’t always land on the last [chord] that you had open, so that was
kind of fun as well to mess with… I definitely liked that random aspect
of the chord system”</p></li>
</ul>
<h4 id="andrew---formant-filters">Andrew - Formant Filters</h4>
<ul>
<li><p>“Cacophonous”</p></li>
<li><p>“It takes a lot of effort”</p></li>
<li><p>“it’s like you’re trying to argue with someone who doesn’t want
to listen to you”</p></li>
<li><p>“…each of your hands are arguing with each other and you just
can’t understand anything that’s going on”</p></li>
<li><p>“it like mimicking how much energy it takes to argue with
someone”</p></li>
<li><p>“I really like and dislike how difficult it is to control the
vowels”</p></li>
<li><p>“especially because each hand does its own vowels it really gives
your hands individual characteristics, it makes them feel like two very
different objects” (incorrect conceptual model)</p></li>
<li><p>“like [your hands] are going against each other rather than
working together”</p></li>
<li><p>“it’s more on the playful side”</p></li>
<li><p>“I do think it’s fun to try to make your hands argue with each
other”</p></li>
</ul>
<h4 id="andrew---concatenative">Andrew - Concatenative</h4>
<ul>
<li><p>“I think I just made the coolest piece”</p></li>
<li><p>“I think this one might actually be my favourite so far out of
all of them… I think what I like most about this one… is when you can
see the point cloud with this one, its almost like you have a map of
planets and each planet has its own different ambience to it, and you
can pick which planet you fly to”</p></li>
<li><p>“what’s nice about it is how it’s limiting, you can’t just [go to
the point you want]”</p></li>
<li><p>“you can be like ‘oh this planet sounds really nice in contrast
to this one’, and try to like jump between the two. And I feel like that
motion is really fun”</p></li>
<li><p>“the way you control the filter in this one is really intuitive I
feel… it’s almost like you’re holding a big ball and depending on how
you move the ball around the space - whether it’s a big ball or a small
ball - and how you twist your hands around it, it creates the sound in
that way”</p></li>
<li><p>“I feel like this one works really well the way it is”</p></li>
<li><p>“it’s slightly annoying that you can’t just pick exactly where it
is [the position that determines the playback slice of audio] but also
that’s like kind of one of my favourite parts about it”</p></li>
<li><p>“the pan position wasn’t really easily controllable but I didn’t
really need it to be”</p></li>
<li><p>“it feels less like an audio tool… I would say this one feels
more playful”</p></li>
</ul>
<h4 id="andrew---magic-spells">Andrew - Magic Spells</h4>
<ul>
<li><p>“that one’s so fun, that one’s really fun”</p></li>
<li><p>“I like how it has the slight bit of control and randomisation…
even though it’s charging the same spell… the slight variation makes it
much more engaging”</p></li>
<li><p>“this one’s definitely I think the most fun out of all of them… I
don’t know if it’s my favourite one but I think it’s the most playful
one for sure”</p></li>
<li><p>“it’s very satisfying to have almost full control over something…
because it’s so simple I think that makes it really satisfying”</p></li>
<li><p>“I feel like the controls in this one are simpler than the
others… it has very few things that you can tell that you’re controlling
at least, regardless of how many things are going on under the
surface”</p></li>
<li><p>“it really feels like you have this power in your hands now
through this one, I don’t know if it’s because of the sounds or the
connotations of magic spells… but it’s very fun to just [makes spell
noises] you really feel like you’re just throwing spells at
somebody”</p></li>
<li><p>“if it loses track of your hands [it’s frustrating] - I’m like
‘aw damn it’… I just wish I didn’t lose track of my hands… just hearing
the charge of the spell die down is just like [makes disappointed
noise]”</p></li>
<li><p>“I really like the different charging times of the different
spells”</p></li>
<li><p>“it’s fun to play with how you can combine the two
spells”</p></li>
<li><p>“I definitely feel like this one feels more playful or like a
game”</p></li>
</ul>
<h4 id="lyla---scrubbing-explorer">Lyla - Scrubbing Explorer</h4>
<ul>
<li><p>“it’s kind of like an investigation”</p></li>
<li><p>“it’s very different from playing an instrument you can touch or
a tool you can actually move”</p></li>
<li><p>“it kind of takes a while to figure out how far you can [move
your hands]… it becomes more intuitive as you go”</p></li>
<li><p>“it’s kind of similar to how you would have to change the
pressure of a bow on a string, when you’re playing on strings of
different thickness on a stringed instrument… where you have to adjust
what you’re doing according to which string you’re on, so in this case
it felt analogous to how you’re changing between the different
files”</p></li>
<li><p>“I enjoyed figuring out the boundaries of what you can do…
because you have so many settings, it’s simple in terms of what’s there,
but then because of the number of endless combinations you can
have”</p></li>
<li><p>“you would expect it to be more consistent, but because sometimes
I found that it wasn’t like perfect (or maybe I was doing something
wrong), it was really cool to hear a sound that I was expecting come out
slightly different. So figuring that out as I played with it was really,
really cool”</p></li>
<li><p>“it was really cool to sometimes combine [the sounds]”</p></li>
<li><p>“one thing I didn’t like was… sometimes when you move your hand
too fast… sometimes your hand would disappear”</p></li>
<li><p>“similar to the frustrations of like figuring out the limitations
of, for example, the violin… I need to figure out the right pressure and
technique to avoid having that sound that you don’t want to maintain
that consistency”</p></li>
<li><p>“consistency was one thing I wasn’t like very comfortable with…
but that’s what I kind of like about it too, it kind of breaks your
expectations”</p></li>
<li><p>“it felt like I was playing around with the pedals of a harp… I
enjoyed it in that way, when I was doing it I didn’t feel like I was
just pressing buttons to get a sound… I needed to create the sound
myself so I needed to figure it out and get familiar with it”</p></li>
<li><p>“you couldn’t really hold tones for very long which is another
thing I wasn’t very happy with, but it was really cool because it
wouldn’t last so you would have to depend on the velocity of your hand
and that sort of action, and know that you’re not going to get it to go
on forever. So that was really fun to play around with”</p></li>
</ul>
<h4 id="lyla---piano-clouds">Lyla - Piano Clouds</h4>
<ul>
<li><p>“it was meditative, because I guess there weren’t as many options
[as the scrubber explorer]”</p></li>
<li><p>“I felt more like I was playing with like a Brian Eno iphone game
[<em>Bloom</em> by Brian Eno and Peter Chilvers]”</p></li>
<li><p>“it felt like the world I was in was smaller and more
simple”</p></li>
<li><p>“[my favourite thing was] thinking if this was a composition, how
would I change the chords according to the emotion I want”</p></li>
<li><p>“its not very jarring, the way the tones are played are more
monotonous… I really enjoyed that”</p></li>
<li><p>“I really like that you organised them into chords… I find that
it’s easier to associate feelings and colours and like a world with a
chord, so being able to play around with these specific chords… it felt
really nice to experiment with the changes”</p></li>
<li><p>“if you move too fast then it sounds like you’re hitting the same
note like three times and that impact, I just found it a little bit
annoying because - one, it’s not natural sounding to what an actual
piano would sound like, two, the same note being hit multiple times when
it’s not in character with the rest of what’s going on… I feel like it’s
meant to be more of a peaceful experience… but those moments would catch
me off guard”</p></li>
<li><p>“it felt nice that I didn’t have to think as much with it, I can
kind of just loose myself in the tool rather than think about what I’m
doing with the tool”</p></li>
<li><p>“it felt creative in that I could change how it made me feel,
with the chords and the speeds. But other than that it felt meditative
because it was so simple”</p></li>
</ul>
<h4 id="lyla---formant-filters">Lyla - Formant Filters</h4>
<ul>
<li><p>“it was eye-opening in that it kind of made me think about the
shape of my own mouth when I’m speaking vs. the shapes that I’m making
with my hands and the vowels that are being made”</p></li>
<li><p>“I found this a little bit more confusing compared to the other
ones because it took a lot more getting used to the controls to be able
to make specific sounds.”</p></li>
<li><p>“it feels more complicated compared to the other ones… not
because of what’s there but because of what I’m having to do with my
hands”</p></li>
<li><p>“I enjoyed the vowel changes… I wasn’t sure if I was doing it
right… it felt more natural to do this [rotated hand]” (compared to the
mapping of fist to vowel)</p></li>
<li><p>“it was really cool to hear human voice like sounds, and being
able to manipulate it on the spot”</p></li>
<li><p>“when you get to a certain spot it loses the hand and then it’ll
just go back to doing like [a different vowel sound] rather than
whatever other vowel I was actually doing which was slightly annoying.
Also the fact that I couldn’t lengthen [the sound envelope]”</p></li>
<li><p>“Once you understand the association of the shape of the hand
with the vowel it can be really cool to play around with”</p></li>
<li><p>“it felt more educational… I felt like playing around with it
made me more attentive to how subtle changes even with this tool could
change how something sounds so easily, and it made me think about the
phonetic alphabet and my own mouth and everything. So it kind of made me
pay more attention - in that sense it was eye-opening”</p></li>
<li><p>“the association I had with [the sound] felt more personal
because it’s closer to a human voice, so in that sense the tool felt
easier for me to understand in terms of like conceptually what it is but
in terms of like how to control it, it took more effort. But I feel like
if the controls were a little bit more fluid it could be even more
educational and more of an experimental tool”</p></li>
</ul>
<h4 id="lyla---concatenative">Lyla - Concatenative</h4>
<ul>
<li><p>“I’m a very big fan… I really enjoyed it”</p></li>
<li><p>“it was fun because it felt like you were exploring a map - a
topographical map but instead of everything being kind of 2D it’s 3D
because the translation is like in your hands. So it felt like you were
kind of extracting that out of the computer and then making it into a 3
dimensional world which I really, really liked.”</p></li>
<li><p>“I kind of like having the [visual] map because it makes it
easier for me to navigate vs. like the vowel one you really had to
listen”</p></li>
<li><p>“I like the variation in all the different sound options there
are”</p></li>
<li><p>“I love the filter… it was very consistent throughout all of the
settings and… the freedom that I had and the sensitivity, it works well
with the sensor - I felt like it was easier to control in this
one”</p></li>
<li><p>“it gives you the liberty to explore each dot [audio slice]
separately and then there’s also that like bigger motion of
experimenting with this map as a whole”</p></li>
<li><p>“it would quickly inform you what each of the settings do - like
what the filter does to the sound”</p></li>
<li><p>“it felt more like I was playing with it this time compared to
the other ones”</p></li>
<li><p>“I feel like when you feel more freedom… the more intuitive and
easier it is to play with a sound with an instrument, the more you can
enjoy it. Like it doesn’t feel good to play the violin when all you can
create are screechy noises… the satisfaction comes when you’re able to
sub-consciously have all of the foundations set in place… when you can
actually create a sound and then you can play with a sound to make it
misbehave or behave… in that way because it was so much easier to access
all of the different features of this program, it felt more fun for me -
it felt like play.”</p></li>
<li><p>“the fact that it’s so much easier to hear the effect [of your
actions] …that makes it so much easier”</p></li>
</ul>
<h4 id="lyla---magic-spells">Lyla - Magic Spells</h4>
<ul>
<li><p>“it was satisfying, but in a different way to [the concatenative
interaction]”</p></li>
<li><p>“it’s playing around with like the anticipation of a sound or
like the result that you expect”</p></li>
<li><p>“I immediately enjoyed how audio-visual cues from the Magic Spell
Interaction subjects you to a pressuring push-and-pull sensation,
playing off of the excitement of anticipation, until you, yourself,
experiment with the intensity and timing of the release to achieve a
“desired” sound. I also appreciated the option to explore the
amalgamated and separate outputs from the L/R hands and felt
particularly excited upon discovering the very wet mechanical sounds as
I moved my R hand further away from the sensor and found myself
comparing their profile to that of other sounds.”</p></li>
<li><p>“I was slightly annoyed by how the sensor did not always pick up
what I was doing with my hands, resulting in the perturbed access of the
extra noises or the unsatisfying experience of withering sound from a
semi-charged “battery” when the hands were no longer registered by the
sensor. I also felt like I wanted to have the freedom to orchestrate the
charging speed of the respective batteries, which was not available.
However, it was cool to notice the change in my emotional response to
these issues over time, as I was able to positively accredit the subtle
frustration for making the interaction feel more game-like, eventually
sparking a very different sense of joy.” <br><br></p></li>
</ul>
<h3
id="section-2-future-flavours-of-sound-festival-feedback"><strong>Section
2:</strong> Future Flavours of Sound Festival Feedback</h3>
<p><strong><em>This section includes some quotes taken from Yann Seznec
and Jacob Sachs Mishalanie during the</em></strong> <strong>Future
Flavours of Sound Festival 2022</strong>, <strong><em>where I shared
videos of the FM Velocity Synth and an early prototype of the Formant
Filter interaction. These are some selected quotes from the direct
feedback I got from Yann and Jake. For the full discussion you can see
the video of the event <a href="https://youtu.be/iCKRifnjdDA?t=4246"
title="Future Flavours of Sound 2022: Audio Programming and Technologies">here</a>
(the discussion of my work falls between approximately 01:10:44 and
01:36:30).</em></strong></p>
<ul>
<li><p>“oh man, it’s really nice that it’s like, I guess, velocity
based? …it’s amazing how simple that feels, and yet it’s very effective
because it means you can hold your hands still and there’s no sound and
that’s a very strong sonic interaction kind of thing was actually
managing silence. Because managing silence in anything that involves
movement is very hard - especially anything that involves direct mapping
of movement… so that I thought was really effective.” (01:16:22) [Yann
Seznec]</p></li>
<li><p>“Leaning into [fist opening and closing] was a good choice
because from a sound design perspective and a sound interaction
perspective, closing your hand for me definitely has that kind of
filtering feel… it works - that connection is very strong… you don’t
even notice it happening because it’s such a strong interaction.”
(01:35:14) [Yann Seznec]</p></li>
<li><p>“…the vowel thing, that was fucking awesome… that was something I
had not expected at all.” (01:19:18) [Yann Seznec]</p></li>
<li><p>“…if you want to sort of like make it fun or something, it would
be cool if this feels interactive between multiple people… it could be
much more fun if two people get up and then they have to figure out how
to do something together.” (01:24:12) [Jacob Sachs-Mishalanie]</p></li>
<li><p>“…it might be interesting to have some more things happening in
the space that you’re interacting with that are a little bit harder to
understand so that there’s a little bit of a discovery game happening.”
(01:27:19) [Jacob Sachs-Mishalanie] <br><br></p></li>
</ul>
<h3
id="section-3-some-influential-quotes-from-relevant-literature"><strong>Section
3:</strong> Some Influential Quotes from Relevant Literature</h3>
<p><strong><em>This section includes some further quotes that I noted
from a few selected texts that were particularly inspiring to this
project. They are by no means extensive of the reading that influenced
this project, but as I had them ready at hand in digital format I am
including them here largely for my own future
reference.</em></strong></p>
<h4 id="artful-design-by-ge-wang">3.1: ‘Artful Design’ by Ge Wang</h4>
<ul>
<li><p>“Principle 4.5: Design things <strong>with</strong> a computer
that would <strong>not</strong> be possible <strong>without</strong>! Do
not simply copy, port, digitise, or emulate. Rather, create something
novel and unique to the <strong>medium</strong> – something that
<strong>could not exist</strong> without it… Design to the medium!”
(pg.181)</p></li>
<li><p>“The sublime is not a feature to put into a product, but a
consequence of experience. To design artfully is to design with
authenticity, to shape things that strive for deep beauty: a harmony of
form and function in search of truth, clarity, an ideal, and out common
humanity. Transcending sheer utility, sublime design strives to
understand who we are and who we want to be.” (pg.50)</p></li>
<li><p>“…there is great joy in the crafting of a tool and the implicit
set of ideas it embodies – presenting a different mindset while hiding
complexities that the user shouldn’t have to think about.”
(pg.200)</p></li>
<li><p>“Aesthetically [a software system] represents a way of working,
playing and living with computers and the things we make.”
(pg.203)</p></li>
<li><p>“Design connects the medium to the message. The art of design
draws from the essential qualities of a medium, to create something that
would not and could not exist as meaningfully in another medium. The
medium should become the message so completely that the medium seemingly
melts away, leaving only the essential message - and the illusion that
the medium doesn’t matter. However, this is only an illusion, for the
medium matters fundamentally: it is how we unfold the message.”
(pg.205)</p></li>
<li><p>“In a time of rapidly increasing automation, the artful designer
must be cognizant of situations in which it is essential to design the
human into the loop. Interfaces ought to extend us, make us feel a sense
of embodiment in their use, giving us new hands to interact with the
world around us.” (pg.206)</p></li>
<li><p>“All musical instruments are interfaces, a kind of implicit
contract of interaction between a player and an underlying mechanism of
sound production. The interaction between them manifests itself as an
active, ongoing feedback loop – a dynamic process, one in which we are
constantly evaluating the results of our actions, ever fine-tuning the
relationship.” (pg.207)</p></li>
<li><p>“…the most effective and elegant interactions are the result of
interfaces that mediate and seamlessly bind the user and the artefact
into a single system.” (pg.207)</p></li>
<li><p>“The result may reside below out conscious notice, but
interaction always induces a consequence of experience, a flavour to the
encounter.” (pg.208)</p></li>
<li><p>“The aesthetics of interaction lie in the elegance and
expressiveness of use.” (pg.208)</p></li>
<li><p>“Instrument design in an extreme form of interface design.
Deceptively tricky, it demands both simplicity of interaction and the
potential for complexity and richness in its output.” (pg.208)</p></li>
<li><p>“An instrument is a tool: it exists because it offers at least
one core aspect, however subtle, that it does better than anything
else.” (pg.209)</p></li>
<li><p>“…it was hands that were the working surface, the hands that felt
and manipulated the universe, human beings thought with their hands. It
was their hands that were the answer of curiosity, that felt and pinched
and turned and lifted and hefted. There were animals that had brains of
respectable size, but they had no hands and that made all the
difference.” (Isaac Asimov, Foundation’s Edge)</p></li>
<li><p>“The many types of gestures our bodies are capable of making give
rise to technologies to sense them; they are the building blocks of
interface design.” (pg.211)</p></li>
<li><p>“We tend to think of computers, algorithms, machine learning, and
artificial intelligence as pure automation that produces some output –
and it’s easy to overlook their potential for human interaction, but
many things computers can do can be fundamentally improved by placing
human intentionality, tacit knowledge, instinct, and aesthetics into the
interaction loop – embodying the idea that computers ought not be
replacements but extensions of us.” (pg.218)</p></li>
<li><p>“authentic synthesis of technology and the human is not only
possible but truly interesting.” (pg.219)</p></li>
<li><p>“<strong>Funny</strong> is often better than
<strong>serious</strong>… <strong>wit</strong> is never a bad thing in
design! It can offer humour, interest, commentary, or
<strong>whimsy</strong> (an art in itself).” (quoting Perry Cook,
pg.288)</p></li>
<li><p>“…I don’t believe in <em>top-down</em> design; I tinker, I
<em>make</em>, I try to craft a <em>piece</em> – not an
<em>instrument</em> (the latter naturally emerges out of necessity).”
(pg.290, Perry Cook)</p></li>
<li><p>“…the programmability of computer-based music systems often makes
them <em>too easy</em> to configure, redefine, remap, etc. For
programmers and composers, this provides an <em>infinite landscape</em>
for experimentation, creativity, writing papers, wasting time, and
<em>never</em> actually completing any art projects or compositions!”
(pg.290, Perry Cook)</p></li>
<li><p>“When people think of computers, they often think of computers
being ‘smart’ and somehow <em>adapting</em> to you. I am <em>less</em>
interested in an instrument that <em>wants to learn me</em> – and
<em>more</em> in an instrument that <em>allows me</em> to learn
<em>it</em>!” (pg.291, Perry Cook)</p></li>
<li><p>“…what is the instrument designer’s <em>imperative</em> in this
age of <em>technology</em>? …it’s <em>not</em> necessarily to make
<em>generalised</em> instruments that others can learn (such as a
luthier or violin maker does) rather the <em>imperative</em> is for our
own <em>process</em>.” (pg.298)</p></li>
<li><p>“Design as one’s own artistic exploration.” (pg.298)</p></li>
<li><p>“…programming as a design medium is now increasingly
<em>accessible</em> to everyone – not necessarily part of a career, but
more like playing an instrument for its sheer <em>intrinsic joy</em> and
experience. It’s a <em>creative tool</em> – no more, no less!”
(pg.299)</p></li>
</ul>
<h4 id="the-design-of-everyday-things-by-don-norman">3.2: ‘The Design of
Everyday Things’ by Don Norman</h4>
<ul>
<li><p>Simplifying levels of human processing into three levels -
although “…a gross oversimplification of the actual processing, it is a
good enough approximation to provide guidance in understanding human
behaviour.” (pg.49)</p></li>
<li><p>The lowest level of human processing as “The visceral level”
involving responses that are quick and subconscious (pg.50)</p></li>
<li><p>“For designers, the visceral response is about immediate
perception… This has nothing to do with how usable, effective, or
understandable the product is. It is all about attraction or repulsion.”
(pg.51)</p></li>
<li><p>The next level of human processing is “The behavioural level,”
which ” is the home of learned skills, triggered by situations that
match the appropriate patterns.” (pg.51)</p></li>
<li><p>“For designers, the most critical aspect of the behavioural level
is that every action is associated with an expectation. Expect a
positive outcome and the result is a positive affective response… Expect
a negative outcome and the result is a negative affective response…
dread and hope, anxiety and anticipation. The information in the
feedback loop of evaluation confirms or disconfirms the expectations,
resulting in satisfaction or relief, disappointment or frustration.”
(pg.52)</p></li>
<li><p>“Behavioural states are learned. They give rise to a feeling of
control when there is good understanding and knowledge of results, and
frustration and anger when things do not go as planned, and especially
when neither the reason nor the possible remedies are known.”
(pg.52)</p></li>
<li><p>“Feedback provides reassurance, even when it indicates a negative
result. A lack of feedback creates a feeling of lack of control, which
can be unsettling. Feedback s critical to managing expectations, and
good design provides this.” (pg.52)</p></li>
<li><p>The third level of human processing is “The reflective level”
which “is the home of conscious cognition.” (pg.53)</p></li>
<li><p>“Reflection is cognitive, deep, and slow. It often occurs after
the events have happened. It is a reflection or looking back over them,
evaluating the circumstances, actions and outcomes, often assessing
blame or responsibility. The highest level of emotions come from the
reflective level, for it is here that causes are assigned and where
predictions of the future take place. Adding causal elements to
experienced events leads to such emotional states as guilt and pride
(when we assume ourselves to be the cause) and blame and praise (when
others are thought to be the cause).” (pg.53)</p></li>
<li><p>“The behavioural level, which is the home of interaction, is also
home of all expectation-based emotions, of hope and joy, frustration and
anger. Understanding arises at a combination of the behavioural and
reflective levels. Enjoyment requires all three.” (pg.54)</p></li>
<li><p>“…badly designed devices can induce frustration and anger, a
feeling of helplessness and despair, and possibly even hate.
Well-designed devices can induce pride and enjoyment, a feeling of being
in control and pleasure - possibly even love and attachment.”
(pg.55)</p></li>
<li><p>“One important emotional state is the one that accompanies
complete immersion into an activity, a state that the social scientist
Mihaly Csikszentmihalyi has labelled ‘flow’. Csikszentmihalyi has long
studied how people interact with their work and play, and how their
lives reflect this intermix of activities. When in the flow state,
people lose track of time and the outside environment. They are at one
with the task they are performing. The task, moreover, is at just the
proper level of difficulty: difficult enough to provide a challenge and
require continued attention, but not so difficult that it invokes
frustration and anxiety.” (pg.55-56)</p></li>
<li><p>“The flow state occurs when the challenge of the activity just
slightly exceeds our skill level, so full attention is continually
required… The constant tension coupled with continual progress and
success can be an engaging, immersive experience sometimes lasting for
hours.” (pg.56)</p></li>
</ul>
<h4 id="cas-holman-design-for-play-abstract-season-2-episode-4">3.3:
‘Cas Holman: Design for Play’ (<em>Abstract</em> Season 2, Episode
4)</h4>
<ul>
<li><p>“We don’t design the play, we design for the circumstances of
play to arise.” (02:15)</p></li>
<li><p>“I like to start with kind of an experiential goal and then
design the object or the system or the playground or whatever it is,
design that around it.” (02:41)</p></li>
<li><p>“…there’s something I think wonderful about when the magnets
don’t meet. And if it had the instructions built into it through colour
coding you would figure out [what didn’t work] and then never do it
wrong and never have that moment.” (08:56)</p></li>
<li><p>“The motto and kind of driving force [of Heroes Will Rise] is
‘<em>easy is boring</em>.’ ‘Easy’ meaning something that doesn’t engage
your thinking.” (11:09)</p></li>
<li><p>“Lots of toys are very goal oriented. They look like something,
there’s one way to play with it. So, you quickly find out it can go this
way or that way and then you’re done. So it sort of shuts down that
building on their own, pleasure and engagement and enjoyment.” (12:41)
[Tovah Klein, Director at Barnard Centre For Toddler
Development]</p></li>
<li><p>“That’s also the point of play is that there’s not an outcome
other than that it’s intuitive.” (20:10)</p></li>
<li><p>“Any toy could be turned into a non-open-ended toy. The way I see
it working against the child is that it says to them, ‘<em>either you do
it right, or you do it wrong</em>.’ If you feel like you aren’t good at
something, you just retreat. Children are curious. They want to engage
with the world, and you give them open-ended toys, they’re much
happier.” (26:25) [Tovah Klein]</p></li>
<li><p>“[An open-ended toy] says to the child, ‘<em>your ideas are
really important.</em>’ Right? Because if you’ve created something and
it was your ideas and now you carried them out, then it’s yours.”
(27:49) [Tovah Klein]</p></li>
<li><p>“Good toys make good people.” (34:33)</p></li>
<li><p>“The driving ethos is ‘<em>what were you curious about?</em>’ And
that’s such a big shift from ‘<em>what did you learn?</em>’ Right? That
there’s an outcome, that there’s a thing that is to be learned, that we
know what can be learned and therefore you’re out to look for it.”
(41:17)</p></li>
</ul>
<h4
id="embodied-user-interfaces-towards-invisible-user-interfaces-fishkin-et-al.-1999">3.4:
‘Embodied User Interfaces: Towards Invisible User Interfaces’, Fishkin
et al. 1999</h4>
<ul>
<li><p>“…the manipulation and the virtual representation are integrated
within the same object, a paradigm which we term Embodied User
Interfaces” (pg.1)</p></li>
<li><p>“…to minimise the cognitive distance between a task goal and the
human actions needed to accomplish that task. We believe these
interaction paradigms are on an evolutionary path towards an ideal of
the invisible user interface,” (pg.2)</p></li>
<li><p>“There is coincidence of input and output in the device.” [in
embodied user interfaces] (pg.3)</p></li>
<li><p>“…the user’s task environment should be embodied within a
physical/computational device, and that this embodied task should be
linked to an analogous real-world task.” (pg.3)</p></li>
</ul>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Perry Cook, quoted in: Ge Wang,
Artful Design: Technology in Search of the Sublime / Written and
Designed by Ge Wang. (Stanford, CA: Stanford University Press, 2018).
pg.288.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>‘Punchdrunk’, accessed 21 August
2022, <a
href="https://www.punchdrunk.com/">https://www.punchdrunk.com/</a>.<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Janet Cardiff, ‘The Missing Voice
(Case Study B) | Artangel’, accessed 22 August 2022, <a
href="https://www.artangel.org.uk/project/the-missing-voice-case-study-b/">https://www.artangel.org.uk/project/the-missing-voice-case-study-b/</a>.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>‘Prof Atau Tanaka’, Goldsmiths,
University of London, accessed 22 August 2022, <a
href="https://www.gold.ac.uk/computing/people/tanaka-atau/">https://www.gold.ac.uk/computing/people/tanaka-atau/</a>.<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>‘MiMU | Home’, accessed 22 August
2022, <a href="https://mimugloves.com/">https://mimugloves.com/</a>.<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>‘Douglas McCausland // Official
Website’, doug-mccausland, accessed 22 August 2022, <a
href="https://www.douglas-mccausland.net">https://www.douglas-mccausland.net</a>.<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Onyx Ashanti, ‘Onyx Ashanti | Speaker
| TED’, accessed 22 August 2022, <a
href="https://www.ted.com/speakers/onyx_ashanti">https://www.ted.com/speakers/onyx_ashanti</a>.<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>‘Michel Waisvisz – DIGITAL ART
(1960-2000)’, accessed 22 August 2022, <a
href="https://www.digitalcanon.nl/?artworks=michel-waisvisz">https://www.digitalcanon.nl/?artworks=michel-waisvisz</a>.<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Donald A. Norman, The Design of
Everyday Things, Revised and expanded edition. (Cambridge,
Massachusetts: The MIT Press, 2013).<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Norman, pg.38<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Norman, pg.38<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>Norman, pg.38<a href="#fnref12"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Norman, pg.40<a href="#fnref13"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>For details on how this play testing
was conducted and an evaluation of it’s limitations, see <a
href="#AppendixE2"><strong>Appendix E, Item 2</strong></a>.<a
href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>Norman, pg.55-56<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>‘Cas Holman: Design For Play’,
Abstract: The Art of Design (Publikro London, RadicalMedia, Tremolo
Productions, 21 January 2017). (timecode - 00:11:09)<a href="#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>Andy Hunt and Ross Kirk, ‘Mapping
Strategies for Musical Performance’, 2000, 28. pg.251<a href="#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>Andy Hunt and Ross Kirk, ‘Mapping
Strategies for Musical Performance’, 2000, 28. pg.251<a href="#fnref18"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>Andy Hunt and Ross Kirk, ‘Mapping
Strategies for Musical Performance’, 2000, 28. pg.251<a href="#fnref19"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p>Andy Hunt and Ross Kirk, ‘Mapping
Strategies for Musical Performance’, 2000, 28. pg.251<a href="#fnref20"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>Tovah Klein, quoted in: Holman,
(timecode - 00:12:41)<a href="#fnref21" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn22" role="doc-endnote"><p>N.B. this patch was used in
conjunction with a reaper project that contained looped audio samples
and the Valhalla Frequency Echo plugin which I have not included in this
project. Therefore this patch is not as ‘playable’ as the others in this
project.<a href="#fnref22" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn23" role="doc-endnote"><p>‘Wekinator | Software for Real-Time,
Interactive Machine Learning’, accessed 22 August 2022, <a
href="http://www.wekinator.org/">http://www.wekinator.org/</a>.<a
href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24" role="doc-endnote"><p>‘Valhalla Freq Echo: Frequency
Shifter Plugin | Free Reverb Plugin’, Valhalla DSP (blog), accessed 22
August 2022, <a
href="https://valhalladsp.com/shop/delay/valhalla-freq-echo/">https://valhalladsp.com/shop/delay/valhalla-freq-echo/</a>.<a
href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25" role="doc-endnote"><p>For a further analysis of this
sensation of joy through surprise, see <a
href="#AppendixE17"><strong>Appendix E, Item 17</strong></a>.<a
href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26" role="doc-endnote"><p>Future Flavours of Sound Festival
2022 - Audio Programming and Technologies, 2022, <a
href="https://www.youtube.com/watch?v=iCKRifnjdDA">https://www.youtube.com/watch?v=iCKRifnjdDA</a>.
(timecode - 01:19:18)<a href="#fnref26" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn27" role="doc-endnote"><p>For details on how this play testing
was conducted and an evaluation of it’s limitations, see <a
href="#AppendixE2"><strong>Appendix E, Item 2</strong></a>.<a
href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28" role="doc-endnote"><p>Atau Tanaka, Embodied Sonic
Interaction: Gesture, Sound and the Everyday, 2013, <a
href="https://www.youtube.com/watch?v=IyOUVixqmTU">https://www.youtube.com/watch?v=IyOUVixqmTU</a>.<a
href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29" role="doc-endnote"><p>For details on how this play testing
was conducted and an evaluation of it’s limitations, see <a
href="#AppendixE2"><strong>Appendix E, Item 2</strong></a>.<a
href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30" role="doc-endnote"><p>Atau Tanaka, Embodied Sonic
Interaction: Gesture, Sound and the Everyday, 2013, <a
href="https://www.youtube.com/watch?v=IyOUVixqmTU">https://www.youtube.com/watch?v=IyOUVixqmTU</a>.<a
href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31" role="doc-endnote"><p>‘Embody’, Collins English Dictionary
– Complete and Unabridged, 12th Edition, 2014, <a
href="https://www.thefreedictionary.com/embody">www.thefreedictionary.com/embody</a>.<a
href="#fnref31" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32" role="doc-endnote"><p>Fishkin et al., ‘Embodied User
Interfaces: Towards Invisible User Interfaces | SpringerLink’, accessed
8 August 2022, <a
href="https://link.springer.com/chapter/10.1007/978-0-387-35349-4_1">https://link.springer.com/chapter/10.1007/978-0-387-35349-4_1</a>.
pg.1<a href="#fnref32" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn33" role="doc-endnote"><p>Fishkin et al., pg.2<a
href="#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34" role="doc-endnote"><p>Wang, pg.238<a href="#fnref34"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn35" role="doc-endnote"><p>Wang, pg.207<a href="#fnref35"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36" role="doc-endnote"><p>Wang, pg.245<a href="#fnref36"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37" role="doc-endnote"><p>‘Sound Design(ed) Futures : New
realities, spaces, technologies’, accessed 27 May 2022, <a
href="https://lisaa.univ-gustave-eiffel.fr/actualites/actualite/sound-designed-futures-new-realities-spaces-technologies">https://lisaa.univ-gustave-eiffel.fr/actualites/actualite/sound-designed-futures-new-realities-spaces-technologies</a>.<a
href="#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn38" role="doc-endnote"><p>To read more about this discussion,
see my blog post on the conference in <a
href="#AppendixE1"><strong>Appendix E, Item 1</strong></a><a
href="#fnref38" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39" role="doc-endnote"><p>Future Flavours of Sound 2022
(timecode - 01:16:22), <a
href="https://www.youtube.com/watch?v=iCKRifnjdDA&amp;t=5797s&amp;ab_channel=FutureFlavoursofSoundFestival">watch
here</a><a href="#fnref39" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn40" role="doc-endnote"><p>Future Flavours of Sound 2022
(timecode - 01:35:14), <a
href="https://www.youtube.com/watch?v=iCKRifnjdDA&amp;t=5797s&amp;ab_channel=FutureFlavoursofSoundFestival">watch
here</a><a href="#fnref40" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn41" role="doc-endnote"><p>For details on how this play testing
was conducted and an evaluation of it’s limitations, see <a
href="#AppendixE2"><strong>Appendix E, Item 2</strong></a>.<a
href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42" role="doc-endnote"><p>For details on how this play testing
was conducted and an evaluation of it’s limitations, see <a
href="#AppendixE2"><strong>Appendix E, Item 2</strong></a>.<a
href="#fnref42" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43" role="doc-endnote"><p>Future Flavours of Sound, <a
href="https://www.youtube.com/watch?v=iCKRifnjdDA&amp;t=5797s&amp;ab_channel=FutureFlavoursofSoundFestival">watch
here</a>.<a href="#fnref43" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
                </div>
            </div>
            <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>
        </div>
    </body>
</html>
